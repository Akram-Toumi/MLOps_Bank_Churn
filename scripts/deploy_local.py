"""
Script de d√©ploiement local du mod√®le
Copie le mod√®le de production depuis MLflow vers le backend et red√©marre l'API
"""

import os
import sys
import pickle
import shutil
import mlflow
import mlflow.sklearn
from pathlib import Path
from datetime import datetime

# Configuration
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://127.0.0.1:5000")
PRODUCTION_MODEL_NAME = "churn_prediction_Stacking_LR"
BACKEND_DIR = Path(__file__).parent.parent / "backend"
NOTEBOOKS_DIR = Path(__file__).parent.parent / "notebooks"
DEPLOYMENT_LOG = Path(__file__).parent.parent / "deployment_log.txt"

print("=" * 80)
print("D√âPLOIEMENT LOCAL DU MOD√àLE")
print("=" * 80)

try:
    # 1. Connexion √† MLflow
    print(f"\nüìä Connexion √† MLflow: {MLFLOW_TRACKING_URI}")
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
    client = mlflow.tracking.MlflowClient()
    
    # 2. R√©cup√©rer le mod√®le de production
    print(f"\nüîç Recherche du mod√®le de production: {PRODUCTION_MODEL_NAME}")
    
    try:
        # Chercher les versions en Production
        production_versions = client.get_latest_versions(PRODUCTION_MODEL_NAME, stages=["Production"])
        
        if not production_versions:
            print(f"‚ö†Ô∏è  Aucun mod√®le en Production trouv√©")
            print(f"   Tentative de r√©cup√©ration de la derni√®re version...")
            
            # Fallback: prendre la derni√®re version enregistr√©e
            all_versions = client.search_model_versions(f"name='{PRODUCTION_MODEL_NAME}'")
            if all_versions:
                production_versions = [max(all_versions, key=lambda x: int(x.version))]
            else:
                raise ValueError(f"Aucune version du mod√®le '{PRODUCTION_MODEL_NAME}' trouv√©e")
        
        prod_version = production_versions[0]
        prod_run_id = prod_version.run_id
        
        print(f"‚úÖ Mod√®le trouv√©:")
        print(f"   Version: {prod_version.version}")
        print(f"   Run ID: {prod_run_id}")
        print(f"   Stage: {prod_version.current_stage}")
        
        # 3. Charger le mod√®le depuis MLflow
        print(f"\nüì• Chargement du mod√®le...")
        model_uri = f"runs:/{prod_run_id}/model"
        model = mlflow.sklearn.load_model(model_uri)
        
        print(f"‚úÖ Mod√®le charg√©: {type(model).__name__}")
        
        # 4. Sauvegarder le mod√®le dans le dossier notebooks
        print(f"\nüíæ Sauvegarde du mod√®le dans {NOTEBOOKS_DIR}...")
        
        # Cr√©er le dossier si n√©cessaire
        NOTEBOOKS_DIR.mkdir(parents=True, exist_ok=True)
        
        # Sauvegarder le mod√®le avec le nom attendu par l'API
        model_filename = "Stacking_LR_ensemble.pkl"
        model_path = NOTEBOOKS_DIR / model_filename
        
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)
        
        print(f"‚úÖ Mod√®le sauvegard√©: {model_path}")
        
        # 5. Cr√©er un fichier de m√©tadonn√©es de d√©ploiement
        deployment_info = {
            "deployed_at": datetime.now().isoformat(),
            "model_name": PRODUCTION_MODEL_NAME,
            "model_version": prod_version.version,
            "run_id": prod_run_id,
            "model_file": model_filename,
            "model_path": str(model_path)
        }
        
        # Sauvegarder les m√©tadonn√©es
        metadata_path = NOTEBOOKS_DIR / "deployment_metadata.json"
        import json
        with open(metadata_path, 'w') as f:
            json.dump(deployment_info, f, indent=2)
        
        print(f"‚úÖ M√©tadonn√©es sauvegard√©es: {metadata_path}")
        
        # 6. Logger le d√©ploiement
        log_message = f"""
{'='*80}
D√âPLOIEMENT R√âUSSI - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'='*80}
Mod√®le: {PRODUCTION_MODEL_NAME}
Version: {prod_version.version}
Run ID: {prod_run_id}
Fichier: {model_filename}
Path: {model_path}
{'='*80}
"""
        
        with open(DEPLOYMENT_LOG, 'a') as f:
            f.write(log_message)
        
        print(f"\n‚úÖ D√©ploiement enregistr√© dans {DEPLOYMENT_LOG}")
        
        # 7. Instructions pour red√©marrer l'API
        print("\n" + "=" * 80)
        print("üìã PROCHAINES √âTAPES")
        print("=" * 80)
        print("\nPour activer le nouveau mod√®le:")
        print("1. Arr√™ter l'API FastAPI si elle est en cours d'ex√©cution")
        print("2. Red√©marrer l'API avec:")
        print(f"   cd {BACKEND_DIR}")
        print("   python api.py")
        print("\nOu si vous utilisez uvicorn directement:")
        print("   uvicorn api:app --reload --host 0.0.0.0 --port 8000")
        
        print("\n" + "=" * 80)
        print("‚úÖ D√âPLOIEMENT TERMIN√â AVEC SUCC√àS")
        print("=" * 80)
        
        sys.exit(0)
        
    except Exception as e:
        print(f"\n‚ùå Erreur lors de la r√©cup√©ration du mod√®le: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
        
except Exception as e:
    print(f"\n‚ùå Erreur lors du d√©ploiement: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
