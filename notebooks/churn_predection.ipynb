{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84a75fd",
   "metadata": {},
   "source": [
    "1. üì¶ Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4405229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports termin√©s\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ML Models\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Imports termin√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133b017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow configur√©\n",
      "üìä Tracking URI: file:///c:\\Users\\Barky\\Documents\\I3\\S1\\MLOps\\Project\\MLOps_Bank_Churn\\notebooks\\mlruns\n",
      "üß™ Experiment: churn_prediction\n",
      "üí° Note: Utilisation d'un backend local (pas de serveur requis)\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION MLFLOW LOCAL (File-based backend)\n",
    "# Utilise un backend local bas√© sur fichiers au lieu d'un serveur\n",
    "MLFLOW_TRACKING_URI = \"./mlruns\"  # Dossier local pour stocker les runs\n",
    "EXPERIMENT_NAME = \"churn_prediction\"\n",
    "\n",
    "# Cr√©er le dossier mlruns s'il n'existe pas\n",
    "os.makedirs(MLFLOW_TRACKING_URI, exist_ok=True)\n",
    "\n",
    "# MLflow local (file-based)\n",
    "mlflow.set_tracking_uri(f\"file:///{os.path.abspath(MLFLOW_TRACKING_URI)}\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# D√©sactiver les features incompatibles (s√©curit√©)\n",
    "os.environ[\"MLFLOW_ENABLE_LOGGED_MODEL_CREATION\"] = \"false\"\n",
    "\n",
    "print(\"‚úÖ MLflow configur√©\")\n",
    "print(f\"üìä Tracking URI: file:///{os.path.abspath(MLFLOW_TRACKING_URI)}\")\n",
    "print(f\"üß™ Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"üí° Note: Utilisation d'un backend local (pas de serveur requis)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2255c90",
   "metadata": {},
   "source": [
    "2. üìÇ Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b820ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es\n",
      "   Train: (42070, 40)\n",
      "   Test: (6000, 40)\n"
     ]
    }
   ],
   "source": [
    "# Charger les donn√©es preprocess√©es\n",
    "DATA_PATH = 'processors/preprocessed_data.pkl'\n",
    "\n",
    "with open(DATA_PATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "\n",
    "print(\"‚úÖ Donn√©es charg√©es\")\n",
    "print(f\"   Train: {X_train.shape}\")\n",
    "print(f\"   Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18cc6a",
   "metadata": {},
   "source": [
    "3. ü§ñ Fonctions Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b635a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonctions utilitaires d√©finies\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer les m√©triques\n",
    "def calculate_metrics(y_true, y_pred, y_proba):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_proba)\n",
    "    }\n",
    "\n",
    "# Fonction pour logger un mod√®le dans MLflow\n",
    "def log_model_mlflow(model, model_name, stage, metrics, duration, best_params=None):\n",
    "    \"\"\"\n",
    "    Log un mod√®le dans MLflow\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_{stage}\"):\n",
    "        # Log params\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        mlflow.log_param('stage', stage)\n",
    "        mlflow.log_param('n_features', X_train.shape[1])\n",
    "        \n",
    "        # Log best params si disponibles\n",
    "        if best_params:\n",
    "            for k, v in best_params.items():\n",
    "                try:\n",
    "                    mlflow.log_param(f'best_{k}', v)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Log metrics\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            mlflow.log_metric(metric_name, metric_value)\n",
    "        mlflow.log_metric('training_duration', duration)\n",
    "        \n",
    "        # Sauvegarder le mod√®le localement\n",
    "        model_filename = f\"{model_name}_{stage}.pkl\"\n",
    "        with open(model_filename, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        \n",
    "        # Log comme artifact\n",
    "        try:\n",
    "            mlflow.log_artifact(model_filename)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        return run_id, model_filename\n",
    "\n",
    "print(\"‚úÖ Fonctions utilitaires d√©finies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f961ca07",
   "metadata": {},
   "source": [
    "4. üöÄ Entra√Ænement des Mod√®les Baseline (4 mod√®les)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b63249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Entra√Ænement des mod√®les BASELINE...\n",
      "\n",
      "üìä XGBoost... ROC-AUC: 0.9995 (2.3s)\n",
      "üìä LightGBM... ROC-AUC: 0.9995 (1.9s)\n",
      "üìä Random_Forest... ROC-AUC: 0.9971 (8.7s)\n",
      "üìä CatBoost... ROC-AUC: 0.9998 (4.0s)\n",
      "üìä Logistic_Regression_ElasticNet... ROC-AUC: 0.9998 (38.0s)\n",
      "\n",
      "‚úÖ Baseline termin√©!\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les mod√®les baseline\n",
    "baseline_config = {\n",
    "        'XGBoost': XGBClassifier(\n",
    "            n_estimators=150,\n",
    "            max_depth=7,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            min_child_weight=3,\n",
    "            gamma=0.1,\n",
    "            random_state=42,\n",
    "            eval_metric='auc',\n",
    "            use_label_encoder=False,\n",
    "            tree_method='hist'\n",
    "        ),\n",
    "        \n",
    "        'LightGBM': LGBMClassifier(\n",
    "            n_estimators=150,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=40,\n",
    "            min_child_samples=25,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1,\n",
    "            importance_type='gain'\n",
    "        ),\n",
    "        \n",
    "        'Random_Forest': RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=25,\n",
    "            min_samples_split=15,\n",
    "            min_samples_leaf=5,\n",
    "            max_features='sqrt',\n",
    "            class_weight='balanced_subsample',\n",
    "            bootstrap=True,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            warm_start=False\n",
    "        ),\n",
    "        \n",
    "        'CatBoost': CatBoostClassifier(\n",
    "            iterations=150,\n",
    "            depth=7,\n",
    "            learning_rate=0.05,\n",
    "            l2_leaf_reg=3,\n",
    "            border_count=128,\n",
    "            auto_class_weights='Balanced',\n",
    "            random_state=42,\n",
    "            verbose=False,\n",
    "            task_type='CPU',\n",
    "            bootstrap_type='Bernoulli',\n",
    "            subsample=0.85\n",
    "        ),\n",
    "        \n",
    "        'Logistic_Regression_ElasticNet': LogisticRegression(\n",
    "            penalty='elasticnet',\n",
    "            C=1.0,\n",
    "            l1_ratio=0.5,\n",
    "            solver='saga',\n",
    "            max_iter=1000,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            warm_start=False\n",
    "        )\n",
    "    }\n",
    "\n",
    "baseline_results = []\n",
    "trained_models = {}\n",
    "\n",
    "print(\"üöÄ Entra√Ænement des mod√®les BASELINE...\\n\")\n",
    "\n",
    "for name, model in baseline_config.items():\n",
    "    print(f\"üìä {name}...\", end=\" \")\n",
    "    start = datetime.now()\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©triques\n",
    "    metrics = calculate_metrics(y_test, y_pred, y_proba)\n",
    "    duration = (datetime.now() - start).total_seconds()\n",
    "    \n",
    "    # Log dans MLflow\n",
    "    run_id, model_file = log_model_mlflow(model, name, 'baseline', metrics, duration)\n",
    "    \n",
    "    # Stocker\n",
    "    trained_models[f\"{name}_baseline\"] = model\n",
    "    baseline_results.append({\n",
    "        'model': name,\n",
    "        'stage': 'baseline',\n",
    "        'run_id': run_id,\n",
    "        **metrics,\n",
    "        'duration': duration\n",
    "    })\n",
    "    \n",
    "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f} ({duration:.1f}s)\")\n",
    "\n",
    "print(\"\\n‚úÖ Baseline termin√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736b15a",
   "metadata": {},
   "source": [
    "5. üîç Fine-Tuning (4 mod√®les avec n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49650541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Fine-Tuning (10 iterations √ó 3 folds)...\n",
      "\n",
      "üìä XGBoost... ROC-AUC: 0.9997 (45.0s)\n",
      "üìä LightGBM... ROC-AUC: 0.9997 (44.9s)\n",
      "üìä Random_Forest... ROC-AUC: 0.9974 (309.6s)\n",
      "üìä CatBoost... ROC-AUC: 0.9998 (245.5s)\n",
      "üìä Logistic_Regression_ElasticNet... ROC-AUC: 0.9999 (236.6s)\n",
      "\n",
      "‚úÖ Fine-tuning termin√©!\n"
     ]
    }
   ],
   "source": [
    "# Grilles de recherche simplifi√©es\n",
    "search_spaces = {\n",
    "        'XGBoost': {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'max_depth': randint(3, 12),\n",
    "            'learning_rate': uniform(0.01, 0.29),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4),\n",
    "            'gamma': uniform(0, 0.5),\n",
    "            'min_child_weight': randint(1, 10),\n",
    "            'reg_alpha': uniform(0, 1),\n",
    "            'reg_lambda': uniform(0, 2)\n",
    "        },\n",
    "        \n",
    "        'LightGBM': {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'max_depth': randint(-1, 15),\n",
    "            'learning_rate': uniform(0.01, 0.29),\n",
    "            'num_leaves': randint(15, 150),\n",
    "            'min_child_samples': randint(10, 60),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4),\n",
    "            'reg_alpha': uniform(0, 1),\n",
    "            'reg_lambda': uniform(0, 2),\n",
    "            'min_split_gain': uniform(0, 0.1)\n",
    "        },\n",
    "        \n",
    "        'Random_Forest': {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'max_depth': [15, 20, 25, 30, 35, None],\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': ['sqrt', 'log2', 0.5, 0.7, 0.9],\n",
    "            'max_samples': uniform(0.7, 0.3),\n",
    "            'class_weight': ['balanced', 'balanced_subsample']\n",
    "        },\n",
    "        \n",
    "        'CatBoost': {\n",
    "            'iterations': randint(100, 500),\n",
    "            'depth': randint(4, 11),\n",
    "            'learning_rate': uniform(0.01, 0.29),\n",
    "            'l2_leaf_reg': uniform(1, 9),\n",
    "            'border_count': [32, 64, 128, 200, 254],\n",
    "            'random_strength': uniform(0, 2)\n",
    "        },\n",
    "        \n",
    "        #Logistic Regression (ElasticNet)\n",
    "        'Logistic_Regression_ElasticNet': {\n",
    "            'C': uniform(0.001, 10),\n",
    "            'l1_ratio': uniform(0, 1),\n",
    "            'max_iter': randint(500, 2000),\n",
    "            'tol': uniform(1e-5, 1e-3)\n",
    "        }\n",
    "    }\n",
    "\n",
    "tuned_results = []\n",
    "N_ITER = 10  # Nombre d'it√©rations\n",
    "CV_FOLDS = 3\n",
    "\n",
    "print(f\"üîç Fine-Tuning ({N_ITER} iterations √ó {CV_FOLDS} folds)...\\n\")\n",
    "\n",
    "for name, base_model in baseline_config.items():\n",
    "    print(f\"üìä {name}...\", end=\" \")\n",
    "    start = datetime.now()\n",
    "    \n",
    "    # RandomizedSearchCV\n",
    "    search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        search_spaces[name],\n",
    "        n_iter=N_ITER,\n",
    "        cv=CV_FOLDS,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©triques\n",
    "    metrics = calculate_metrics(y_test, y_pred, y_proba)\n",
    "    duration = (datetime.now() - start).total_seconds()\n",
    "    \n",
    "    # Log dans MLflow\n",
    "    run_id, model_file = log_model_mlflow(\n",
    "        best_model, name, 'tuned', metrics, duration, search.best_params_\n",
    "    )\n",
    "    \n",
    "    # Stocker\n",
    "    trained_models[f\"{name}_tuned\"] = best_model\n",
    "    tuned_results.append({\n",
    "        'model': name,\n",
    "        'stage': 'tuned',\n",
    "        'run_id': run_id,\n",
    "        **metrics,\n",
    "        'duration': duration\n",
    "    })\n",
    "    \n",
    "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f} ({duration:.1f}s)\")\n",
    "\n",
    "print(\"\\n‚úÖ Fine-tuning termin√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b815875",
   "metadata": {},
   "source": [
    "6. üéØ Stacking Ensembles (4 mod√®les)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae6b2424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Entra√Ænement des mod√®les ENSEMBLE...\n",
      "\n",
      "üìä Stacking (LogReg)... \n",
      "üß† Meta-Learner (Stacking):\n",
      "   ‚Ä¢ Type: LogisticRegression\n",
      "   ‚Ä¢ Configuration: R√©gularisation ElasticNet\n",
      "ROC-AUC: 0.9999 (355.2s)\n",
      "üìä Voting (Soft)... ROC-AUC: 0.9998 (85.2s)\n",
      "\n",
      "‚úÖ Ensembles termin√©s!\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    #('xgb', trained_models['XGBoost_tuned']),\n",
    "    ('lgbm', trained_models['LightGBM_tuned']),\n",
    "    ('rf', trained_models['Random_Forest_tuned']),\n",
    "    ('cat', trained_models['CatBoost_tuned']),\n",
    "    ('lr', trained_models['Logistic_Regression_ElasticNet_tuned'])\n",
    "]\n",
    "\n",
    "ensemble_results = []\n",
    "\n",
    "meta_learner_config=None\n",
    "\n",
    "print(\"üöÄ Entra√Ænement des mod√®les ENSEMBLE...\\n\")\n",
    "\n",
    "# 1. Stacking avec Logistic Regression\n",
    "print(\"üìä Stacking (LogReg)...\", end=\" \")\n",
    "\n",
    "if meta_learner_config is None:\n",
    "    meta_learner = LogisticRegression(\n",
    "        penalty='elasticnet',\n",
    "        C=0.5,\n",
    "        l1_ratio=0.3,\n",
    "        solver='saga',\n",
    "        max_iter=1500,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "    meta_learner = meta_learner_config\n",
    "\n",
    "print(f\"\\nüß† Meta-Learner (Stacking):\")\n",
    "print(f\"   ‚Ä¢ Type: {type(meta_learner).__name__}\")\n",
    "print(f\"   ‚Ä¢ Configuration: R√©gularisation ElasticNet\")\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "stacking_lr = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=meta_learner,\n",
    "        cv=5,\n",
    "        stack_method='predict_proba',\n",
    "        n_jobs=-1,\n",
    "        passthrough=False,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "stacking_lr.fit(X_train, y_train)\n",
    "y_pred = stacking_lr.predict(X_test)\n",
    "y_proba = stacking_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics_stack_lr = calculate_metrics(y_test, y_pred, y_proba)\n",
    "duration = (datetime.now() - start).total_seconds()\n",
    "\n",
    "run_id_lr, _ = log_model_mlflow(stacking_lr, 'Stacking_LR', 'ensemble', metrics_stack_lr, duration)\n",
    "trained_models['Stacking_LR'] = stacking_lr\n",
    "ensemble_results.append({\n",
    "    'model': 'Stacking_LR',\n",
    "    'stage': 'ensemble',\n",
    "    'run_id': run_id_lr,\n",
    "    **metrics_stack_lr,\n",
    "    'duration': duration\n",
    "})\n",
    "\n",
    "print(f\"ROC-AUC: {metrics_stack_lr['roc_auc']:.4f} ({duration:.1f}s)\")\n",
    "\n",
    "# 2. Voting Classifier (soft voting)\n",
    "print(\"üìä Voting (Soft)...\", end=\" \")\n",
    "start = datetime.now()\n",
    "\n",
    "voting_soft = VotingClassifier(\n",
    "        estimators=estimators,\n",
    "        voting='soft',\n",
    "        n_jobs=-1,\n",
    "        flatten_transform=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "voting_soft.fit(X_train, y_train)\n",
    "y_pred = voting_soft.predict(X_test)\n",
    "y_proba = voting_soft.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics_voting_soft = calculate_metrics(y_test, y_pred, y_proba)\n",
    "duration = (datetime.now() - start).total_seconds()\n",
    "\n",
    "run_id_soft, _ = log_model_mlflow(voting_soft, 'Voting_Soft', 'ensemble', metrics_voting_soft, duration)\n",
    "trained_models['Voting_Soft'] = voting_soft\n",
    "ensemble_results.append({\n",
    "    'model': 'Voting_Soft',\n",
    "    'stage': 'ensemble',\n",
    "    'run_id': run_id_soft,\n",
    "    **metrics_voting_soft,\n",
    "    'duration': duration\n",
    "})\n",
    "\n",
    "print(f\"ROC-AUC: {metrics_voting_soft['roc_auc']:.4f} ({duration:.1f}s)\")\n",
    "\n",
    "print(\"\\n‚úÖ Ensembles termin√©s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe7ab40",
   "metadata": {},
   "source": [
    "7. üìä Lecture des R√©sultats avec Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e36d160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä R√©sultats de tous les mod√®les:\n",
      "\n",
      "                         model    stage  roc_auc  f1_score   duration\n",
      "                       XGBoost baseline 0.999531  0.964048   2.297465\n",
      "                      LightGBM baseline 0.999535  0.966711   1.887083\n",
      "                 Random_Forest baseline 0.997076  0.917431   8.663865\n",
      "                      CatBoost baseline 0.999789  0.971504   3.996373\n",
      "Logistic_Regression_ElasticNet baseline 0.999817  0.948784  37.959722\n",
      "                       XGBoost    tuned 0.999704  0.973666  44.975532\n",
      "                      LightGBM    tuned 0.999744  0.972428  44.945735\n",
      "                 Random_Forest    tuned 0.997352  0.918489 309.632431\n",
      "                      CatBoost    tuned 0.999765  0.977058 245.529327\n",
      "Logistic_Regression_ElasticNet    tuned 0.999899  0.954282 236.558460\n",
      "                   Stacking_LR ensemble 0.999905  0.985953 355.159677\n",
      "                   Voting_Soft ensemble 0.999842  0.977303  85.174074\n",
      "\n",
      "üèÜ Top 5 mod√®les (ROC-AUC):\n",
      "\n",
      "                         model    stage  roc_auc  f1_score\n",
      "                   Stacking_LR ensemble 0.999905  0.985953\n",
      "Logistic_Regression_ElasticNet    tuned 0.999899  0.954282\n",
      "                   Voting_Soft ensemble 0.999842  0.977303\n",
      "Logistic_Regression_ElasticNet baseline 0.999817  0.948784\n",
      "                      CatBoost baseline 0.999789  0.971504\n"
     ]
    }
   ],
   "source": [
    "# Combiner tous les r√©sultats\n",
    "all_results = baseline_results + tuned_results + ensemble_results\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"üìä R√©sultats de tous les mod√®les:\\n\")\n",
    "print(df_results[['model', 'stage', 'roc_auc', 'f1_score', 'duration']].to_string(index=False))\n",
    "\n",
    "# Afficher le top 5 par ROC-AUC\n",
    "print(\"\\nüèÜ Top 5 mod√®les (ROC-AUC):\\n\")\n",
    "top5 = df_results.nlargest(5, 'roc_auc')[['model', 'stage', 'roc_auc', 'f1_score']]\n",
    "print(top5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9239388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Lecture depuis MLflow...\n",
      "\n",
      "                             run_id               params.model_name  \\\n",
      "0  b72341500b49443c96727e61083a457d                     Stacking_LR   \n",
      "1  e99dc336e4e6454cb917caaf0186c1ca  Logistic_Regression_ElasticNet   \n",
      "2  83dececb6b024018925558ac311b3b53                     Voting_Soft   \n",
      "3  d89c44df92fe4cf2b35d2de2bb03e1cb  Logistic_Regression_ElasticNet   \n",
      "4  d663194d575441f9997fddab193d141e                        CatBoost   \n",
      "5  9598077b632f4bf3b657aa0cf2437df0                        CatBoost   \n",
      "6  eee47e07b2734cf98d26f00d1c432456                        LightGBM   \n",
      "7  2cf25602ba014a51b64fd1bb1aefb27a                         XGBoost   \n",
      "8  27be18a5ae0448dc8e4ec70320a40fdf                        LightGBM   \n",
      "9  567af913fed840288bd27b85b7781c10                         XGBoost   \n",
      "\n",
      "  params.stage  metrics.roc_auc  metrics.f1_score  metrics.training_duration  \n",
      "0     ensemble         0.999905          0.985953                 355.159677  \n",
      "1        tuned         0.999899          0.954282                 236.558460  \n",
      "2     ensemble         0.999842          0.977303                  85.174074  \n",
      "3     baseline         0.999817          0.948784                  37.959722  \n",
      "4     baseline         0.999789          0.971504                   3.996373  \n",
      "5        tuned         0.999765          0.977058                 245.529327  \n",
      "6        tuned         0.999744          0.972428                  44.945735  \n",
      "7        tuned         0.999704          0.973666                  44.975532  \n",
      "8     baseline         0.999535          0.966711                   1.887083  \n",
      "9     baseline         0.999531          0.964048                   2.297465  \n",
      "\n",
      "‚úÖ 12 runs trouv√©es dans MLflow\n"
     ]
    }
   ],
   "source": [
    "# Lire depuis MLflow directement\n",
    "print(\"\\nüì• Lecture depuis MLflow...\\n\")\n",
    "\n",
    "# Obtenir l'ID de l'experiment\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Rechercher toutes les runs\n",
    "df_mlflow = mlflow.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"metrics.roc_auc > 0\",\n",
    "    order_by=[\"metrics.roc_auc DESC\"]\n",
    ")\n",
    "\n",
    "# Afficher les colonnes importantes\n",
    "if len(df_mlflow) > 0:\n",
    "    cols_to_show = ['run_id', 'params.model_name', 'params.stage', \n",
    "                    'metrics.roc_auc', 'metrics.f1_score', 'metrics.training_duration']\n",
    "    available_cols = [col for col in cols_to_show if col in df_mlflow.columns]\n",
    "    print(df_mlflow[available_cols].head(10))\n",
    "    print(f\"\\n‚úÖ {len(df_mlflow)} runs trouv√©es dans MLflow\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Aucune run trouv√©e dans MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d1bcd",
   "metadata": {},
   "source": [
    "8. üèÜ S√©lection du Meilleur Mod√®le (ROC-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f78158eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ MEILLEUR MOD√àLE (ROC-AUC)\n",
      "============================================================\n",
      "Mod√®le:    Stacking_LR\n",
      "Stage:     ensemble\n",
      "ROC-AUC:   0.9999\n",
      "F1-Score:  0.9860\n",
      "Precision: 0.9775\n",
      "Recall:    0.9946\n",
      "Run ID:    b72341500b49443c96727e61083a457d\n",
      "============================================================\n",
      "\n",
      "‚úÖ Mod√®le charg√© : StackingClassifier\n"
     ]
    }
   ],
   "source": [
    "# Depuis notre DataFrame local\n",
    "best_idx = df_results['roc_auc'].idxmax()\n",
    "best_row = df_results.loc[best_idx]\n",
    "\n",
    "best_model_name = best_row['model']\n",
    "best_stage = best_row['stage']\n",
    "best_run_id = best_row['run_id']\n",
    "best_roc_auc = best_row['roc_auc']\n",
    "\n",
    "print(\"üèÜ MEILLEUR MOD√àLE (ROC-AUC)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mod√®le:    {best_model_name}\")\n",
    "print(f\"Stage:     {best_stage}\")\n",
    "print(f\"ROC-AUC:   {best_roc_auc:.4f}\")\n",
    "print(f\"F1-Score:  {best_row['f1_score']:.4f}\")\n",
    "print(f\"Precision: {best_row['precision']:.4f}\")\n",
    "print(f\"Recall:    {best_row['recall']:.4f}\")\n",
    "print(f\"Run ID:    {best_run_id}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# R√©cup√©rer le mod√®le\n",
    "best_model_key = f\"{best_model_name}_{best_stage}\" if best_stage != 'ensemble' else best_model_name\n",
    "best_model = trained_models.get(best_model_key)\n",
    "\n",
    "print(f\"\\n‚úÖ Mod√®le charg√© : {type(best_model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57556ce1",
   "metadata": {},
   "source": [
    "9. üîÑ Chargement du Mod√®le depuis MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c7182af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Chargement du mod√®le depuis run_id: b72341500b49443c96727e61083a457d\n",
      "\n",
      "‚úÖ Mod√®le charg√© depuis MLflow artifact\n",
      "   Type: StackingClassifier\n",
      "‚úÖ Mod√®le √©galement disponible localement: Stacking_LR_ensemble.pkl\n"
     ]
    }
   ],
   "source": [
    "# Charger le mod√®le depuis le run_id\n",
    "print(f\"üì• Chargement du mod√®le depuis run_id: {best_run_id}\\n\")\n",
    "\n",
    "# Via artifact (compatible DagsHub)\n",
    "try:\n",
    "    # T√©l√©charger l'artifact\n",
    "    model_filename = f\"{best_model_name}_{best_stage}.pkl\"\n",
    "    artifact_uri = f\"runs:/{best_run_id}/{model_filename}\"\n",
    "    \n",
    "    local_path = mlflow.artifacts.download_artifacts(artifact_uri)\n",
    "    \n",
    "    # Charger avec pickle\n",
    "    with open(local_path, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le charg√© depuis MLflow artifact\")\n",
    "    print(f\"   Type: {type(loaded_model).__name__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur de chargement depuis MLflow: {e}\")\n",
    "    print(f\"   Utilisation du mod√®le en m√©moire √† la place\")\n",
    "    loaded_model = best_model\n",
    "\n",
    "# Alternative: Charger depuis fichier local\n",
    "local_model_file = f\"{best_model_name}_{best_stage}.pkl\"\n",
    "if os.path.exists(local_model_file):\n",
    "    with open(local_model_file, 'rb') as f:\n",
    "        loaded_model_local = pickle.load(f)\n",
    "    print(f\"‚úÖ Mod√®le √©galement disponible localement: {local_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d7209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test du mod√®le charg√©...\n",
      "\n",
      "üìä Performances du mod√®le charg√©:\n",
      "   accuracy    : 0.9965\n",
      "   precision   : 0.9775\n",
      "   recall      : 0.9946\n",
      "   f1_score    : 0.9860\n",
      "   roc_auc     : 0.9999\n",
      "\n",
      "üîç Pr√©dictions sur 5 exemples:\n",
      "   Sample 1: Churn=0, Proba=0.0000\n",
      "   Sample 2: Churn=0, Proba=0.0000\n",
      "   Sample 3: Churn=0, Proba=0.0000\n",
      "   Sample 4: Churn=0, Proba=0.0000\n",
      "   Sample 5: Churn=0, Proba=0.0090\n",
      "\n",
      "‚úÖ Mod√®le fonctionne correctement!\n"
     ]
    }
   ],
   "source": [
    "# Test du mod√®le charg√©\n",
    "print(\"\\nüß™ Test du mod√®le charg√©...\\n\")\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "y_proba_loaded = loaded_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# M√©triques\n",
    "test_metrics = calculate_metrics(y_test, y_pred_loaded, y_proba_loaded)\n",
    "\n",
    "print(\"üìä Performances du mod√®le charg√©:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"   {metric:12s}: {value:.4f}\")\n",
    "\n",
    "# Test sur quelques exemples\n",
    "print(\"\\nüîç Pr√©dictions sur 5 exemples:\")\n",
    "sample_predictions = loaded_model.predict(X_test[:5])\n",
    "sample_probas = loaded_model.predict_proba(X_test[:5])[:, 1]\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"   Sample {i+1}: Churn={sample_predictions[i]}, Proba={sample_probas[i]:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Mod√®le fonctionne correctement!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acee5a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/17 20:40:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üì¶ ENREGISTREMENT DANS MLFLOW MODEL REGISTRY\n",
      "================================================================================\n",
      "\n",
      "üîÑ Enregistrement du mod√®le: churn_prediction_Stacking_LR\n",
      "   Run ID: b72341500b49443c96727e61083a457d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/17 20:40:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'churn_prediction_Stacking_LR'.\n",
      "Created version '1' of model 'churn_prediction_Stacking_LR'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le enregistr√© dans MLflow Model Registry\n",
      "   Nom: churn_prediction_Stacking_LR\n",
      "   Version: 1\n",
      "\n",
      "üöÄ Transition vers Production...\n",
      "‚úÖ Mod√®le mis en Production\n",
      "   Stage: Production\n",
      "   Version: 1\n",
      "‚úÖ M√©tadonn√©es ajout√©es (description + tags)\n",
      "\n",
      "üîÑ Test de chargement depuis MLflow Model Registry...\n",
      "\n",
      "‚úÖ Mod√®le charg√© depuis MLflow Registry\n",
      "   URI: models:/churn_prediction_Stacking_LR/Production\n",
      "   Type: StackingClassifier\n",
      "\n",
      "üìä Performances:\n",
      "   accuracy    : 0.9965\n",
      "   precision   : 0.9775\n",
      "   recall      : 0.9946\n",
      "   f1_score    : 0.9860\n",
      "   roc_auc     : 0.9999\n",
      "\n",
      "üß™ Test sur 5 exemples:\n",
      "   Sample 1: Prediction=0\n",
      "   Sample 2: Prediction=0\n",
      "   Sample 3: Prediction=0\n",
      "   Sample 4: Prediction=0\n",
      "   Sample 5: Prediction=0\n",
      "\n",
      "‚úÖ Le mod√®le fonctionne correctement!\n",
      "\n",
      "üìã Versions du mod√®le dans le Registry:\n",
      "\n",
      "Version    Stage           Created              Run ID                                  \n",
      "------------------------------------------------------------------------------------------\n",
      "1          Production      2025-12-17 20:40:53  b72341500b49443c96727e61083a457d        \n",
      "\n",
      "‚úÖ 1 version(s) trouv√©e(s)\n",
      "\n",
      "================================================================================\n",
      "üí° UTILISATION EN PRODUCTION\n",
      "================================================================================\n",
      "\n",
      "# Charger le mod√®le en production:\n",
      "import mlflow\n",
      "\n",
      "model = mlflow.sklearn.load_model(\"models:/churn_prediction_Stacking_LR/Production\")\n",
      "\n",
      "# Faire des pr√©dictions:\n",
      "predictions = model.predict(X_new)\n",
      "probabilities = model.predict_proba(X_new)[:, 1]\n",
      "\n",
      "# Ou charger une version sp√©cifique:\n",
      "model_v1 = mlflow.sklearn.load_model(\"models:/churn_prediction_Stacking_LR/1\")\n",
      "\n",
      "# Ou charger depuis un run_id:\n",
      "model_from_run = mlflow.sklearn.load_model(\"runs:/b72341500b49443c96727e61083a457d/model\")\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ENREGISTREMENT MLFLOW MODEL REGISTRY TERMIN√â\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ ENREGISTREMENT DANS MLFLOW MODEL REGISTRY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Enregistrer le mod√®le dans MLflow Model Registry\n",
    "model_name = f\"churn_prediction_{best_model_name}\"\n",
    "\n",
    "print(f\"\\nüîÑ Enregistrement du mod√®le: {model_name}\")\n",
    "print(f\"   Run ID: {best_run_id}\")\n",
    "\n",
    "try:\n",
    "    # Log le mod√®le avec mlflow.sklearn\n",
    "    with mlflow.start_run(run_id=best_run_id):\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=model_name\n",
    "        )\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le enregistr√© dans MLflow Model Registry\")\n",
    "    print(f\"   Nom: {model_name}\")\n",
    "    \n",
    "    # 2. Obtenir la derni√®re version\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    latest_versions = client.get_latest_versions(model_name, stages=[\"None\"])\n",
    "    \n",
    "    if latest_versions:\n",
    "        latest_version = latest_versions[0].version\n",
    "        print(f\"   Version: {latest_version}\")\n",
    "        \n",
    "        # 3. Transitionner vers Production\n",
    "        print(f\"\\nüöÄ Transition vers Production...\")\n",
    "        client.transition_model_version_stage(\n",
    "            name=model_name,\n",
    "            version=latest_version,\n",
    "            stage=\"Production\",\n",
    "            archive_existing_versions=True\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Mod√®le mis en Production\")\n",
    "        print(f\"   Stage: Production\")\n",
    "        print(f\"   Version: {latest_version}\")\n",
    "        \n",
    "        # 4. Ajouter une description\n",
    "        client.update_model_version(\n",
    "            name=model_name,\n",
    "            version=latest_version,\n",
    "            description=f\"\"\"\n",
    "            Best performing churn prediction model\n",
    "            - Model: {best_model_name}\n",
    "            - Stage: {best_stage}\n",
    "            - ROC-AUC: {best_roc_auc:.4f}\n",
    "            - F1-Score: {best_row['f1_score']:.4f}\n",
    "            - Trained: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        # 5. Ajouter des tags\n",
    "        client.set_model_version_tag(\n",
    "            name=model_name,\n",
    "            version=latest_version,\n",
    "            key=\"model_type\",\n",
    "            value=best_model_name\n",
    "        )\n",
    "        \n",
    "        client.set_model_version_tag(\n",
    "            name=model_name,\n",
    "            version=latest_version,\n",
    "            key=\"training_stage\",\n",
    "            value=best_stage\n",
    "        )\n",
    "        \n",
    "        client.set_model_version_tag(\n",
    "            name=model_name,\n",
    "            version=latest_version,\n",
    "            key=\"roc_auc\",\n",
    "            value=str(round(best_roc_auc, 4))\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ M√©tadonn√©es ajout√©es (description + tags)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur lors de l'enregistrement: {e}\")\n",
    "    print(f\"   Le mod√®le reste disponible via run_id: {best_run_id}\")\n",
    "\n",
    "# 6. Fonction pour charger depuis MLflow Model Registry\n",
    "def load_model_from_registry(model_name, stage=\"Production\"):\n",
    "    \"\"\"\n",
    "    Charge un mod√®le depuis MLflow Model Registry\n",
    "    \n",
    "    Args:\n",
    "        model_name: Nom du mod√®le dans le registry\n",
    "        stage: Stage du mod√®le (Production, Staging, Archived, None)\n",
    "    \n",
    "    Returns:\n",
    "        model: Le mod√®le charg√©\n",
    "    \"\"\"\n",
    "    model_uri = f\"models:/{model_name}/{stage}\"\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    return model\n",
    "\n",
    "# 7. Test de chargement depuis MLflow Registry\n",
    "print(\"\\nüîÑ Test de chargement depuis MLflow Model Registry...\\n\")\n",
    "\n",
    "try:\n",
    "    loaded_model_mlflow = load_model_from_registry(model_name, stage=\"Production\")\n",
    "    \n",
    "    # Test de pr√©diction\n",
    "    y_pred_test = loaded_model_mlflow.predict(X_test[:5])\n",
    "    y_proba_test = loaded_model_mlflow.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculer les m√©triques\n",
    "    mlflow_metrics = calculate_metrics(y_test, loaded_model_mlflow.predict(X_test), y_proba_test)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le charg√© depuis MLflow Registry\")\n",
    "    print(f\"   URI: models:/{model_name}/Production\")\n",
    "    print(f\"   Type: {type(loaded_model_mlflow).__name__}\")\n",
    "    print(f\"\\nüìä Performances:\")\n",
    "    for metric, value in mlflow_metrics.items():\n",
    "        print(f\"   {metric:12s}: {value:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüß™ Test sur 5 exemples:\")\n",
    "    for i in range(5):\n",
    "        print(f\"   Sample {i+1}: Prediction={y_pred_test[i]}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Le mod√®le fonctionne correctement!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur de chargement: {e}\")\n",
    "\n",
    "# 8. Afficher toutes les versions du mod√®le\n",
    "print(\"\\nüìã Versions du mod√®le dans le Registry:\\n\")\n",
    "\n",
    "try:\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    \n",
    "    # R√©cup√©rer toutes les versions\n",
    "    all_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    \n",
    "    if all_versions:\n",
    "        print(f\"{'Version':<10} {'Stage':<15} {'Created':<20} {'Run ID':<40}\")\n",
    "        print(\"-\" * 90)\n",
    "        \n",
    "        for mv in all_versions:\n",
    "            created = datetime.fromtimestamp(mv.creation_timestamp/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"{mv.version:<10} {mv.current_stage:<15} {created:<20} {mv.run_id:<40}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ {len(all_versions)} version(s) trouv√©e(s)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Aucune version trouv√©e\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur: {e}\")\n",
    "\n",
    "# 9. Exemple d'utilisation en production\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° UTILISATION EN PRODUCTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "# Charger le mod√®le en production:\n",
    "import mlflow\n",
    "\n",
    "model = mlflow.sklearn.load_model(\"models:/{model_name}/Production\")\n",
    "\n",
    "# Faire des pr√©dictions:\n",
    "predictions = model.predict(X_new)\n",
    "probabilities = model.predict_proba(X_new)[:, 1]\n",
    "\n",
    "# Ou charger une version sp√©cifique:\n",
    "model_v1 = mlflow.sklearn.load_model(\"models:/{model_name}/1\")\n",
    "\n",
    "# Ou charger depuis un run_id:\n",
    "model_from_run = mlflow.sklearn.load_model(\"runs:/{best_run_id}/model\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ENREGISTREMENT MLFLOW MODEL REGISTRY TERMIN√â\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae8c90",
   "metadata": {},
   "source": [
    "10. üì¶ Enregistrement dans Model Registry (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47a57d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Enregistrement dans Model Registry...\n",
      "\n",
      "‚úÖ Mod√®le enregistr√© dans le registry\n",
      "   Nom: Best_Churn_Stacking_LR\n",
      "   Version: 1.0.0\n",
      "   Stage: production\n",
      "   Path: processors\\model_registry\\Best_Churn_Stacking_LR\\1.0.0\\model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un Model Registry local\n",
    "MODEL_REGISTRY_DIR = Path(\"processors/model_registry\")\n",
    "MODEL_REGISTRY_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def register_model(model, model_name, version=\"1.0.0\", stage=\"production\"):\n",
    "    \"\"\"\n",
    "    Enregistre un mod√®le dans le registry local\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import shutil\n",
    "    \n",
    "    # Cr√©er la structure\n",
    "    model_dir = MODEL_REGISTRY_DIR / model_name.replace(\" \", \"_\")\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    version_dir = model_dir / version\n",
    "    version_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Sauvegarder le mod√®le\n",
    "    model_path = version_dir / \"model.pkl\"\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # M√©tadonn√©es\n",
    "    metadata = {\n",
    "        \"model_name\": model_name,\n",
    "        \"version\": version,\n",
    "        \"stage\": stage,\n",
    "        \"registered_at\": datetime.now().isoformat(),\n",
    "        \"metrics\": test_metrics,\n",
    "        \"run_id\": best_run_id\n",
    "    }\n",
    "    \n",
    "    with open(version_dir / \"metadata.json\", 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    # Lien production\n",
    "    if stage == \"production\":\n",
    "        prod_path = model_dir / \"production.pkl\"\n",
    "        shutil.copy(model_path, prod_path)\n",
    "    \n",
    "    return str(model_path)\n",
    "\n",
    "# Enregistrer le meilleur mod√®le\n",
    "print(\"üì¶ Enregistrement dans Model Registry...\\n\")\n",
    "\n",
    "registry_name = f\"Best_Churn_{best_model_name}\"\n",
    "model_path = register_model(\n",
    "    model=loaded_model,\n",
    "    model_name=registry_name,\n",
    "    version=\"1.0.0\",\n",
    "    stage=\"production\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Mod√®le enregistr√© dans le registry\")\n",
    "print(f\"   Nom: {registry_name}\")\n",
    "print(f\"   Version: 1.0.0\")\n",
    "print(f\"   Stage: production\")\n",
    "print(f\"   Path: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d445f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Test de chargement depuis le registry...\n",
      "\n",
      "‚úÖ Mod√®le charg√© depuis le registry\n",
      "   Nom: Best_Churn_Stacking_LR\n",
      "   Version: 1.0.0\n",
      "   ROC-AUC: 0.9999\n",
      "\n",
      "üß™ Test de pr√©diction: [0 0 0 0 0]\n",
      "‚úÖ Le mod√®le fonctionne correctement!\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour charger depuis le registry\n",
    "def load_from_registry(model_name, stage=\"production\"):\n",
    "    \"\"\"Charge un mod√®le depuis le registry local\"\"\"\n",
    "    import json\n",
    "    \n",
    "    model_dir = MODEL_REGISTRY_DIR / model_name.replace(\" \", \"_\")\n",
    "    model_path = model_dir / f\"{stage}.pkl\"\n",
    "    \n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # Charger les m√©tadonn√©es\n",
    "    versions = [d for d in model_dir.iterdir() if d.is_dir()]\n",
    "    if versions:\n",
    "        latest_version = sorted(versions)[-1]\n",
    "        with open(latest_version / \"metadata.json\", 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "    \n",
    "    return model, metadata\n",
    "\n",
    "# Test du chargement\n",
    "print(\"\\nüîÑ Test de chargement depuis le registry...\\n\")\n",
    "\n",
    "loaded_from_registry, metadata = load_from_registry(registry_name, stage=\"production\")\n",
    "\n",
    "print(f\"‚úÖ Mod√®le charg√© depuis le registry\")\n",
    "print(f\"   Nom: {metadata.get('model_name', 'N/A')}\")\n",
    "print(f\"   Version: {metadata.get('version', 'N/A')}\")\n",
    "print(f\"   ROC-AUC: {metadata.get('metrics', {}).get('roc_auc', 0):.4f}\")\n",
    "\n",
    "# Test de pr√©diction\n",
    "test_pred = loaded_from_registry.predict(X_test[:5])\n",
    "print(f\"\\nüß™ Test de pr√©diction: {test_pred}\")\n",
    "print(\"‚úÖ Le mod√®le fonctionne correctement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75338d",
   "metadata": {},
   "source": [
    "11. üìä R√©sum√© Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "438d3d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéâ R√âSUM√â FINAL - MLflow Tracking\n",
      "================================================================================\n",
      "\n",
      "üìä Mod√®les entra√Æn√©s:\n",
      "   ‚Ä¢ Baseline:  5 mod√®les\n",
      "   ‚Ä¢ Tuned:     5 mod√®les (n_iter=10)\n",
      "   ‚Ä¢ Ensemble:  2 mod√®les (Stacking + Voting)\n",
      "   ‚Ä¢ TOTAL:     12 mod√®les\n",
      "\n",
      "üèÜ Meilleur mod√®le:\n",
      "   ‚Ä¢ Nom:       Stacking_LR\n",
      "   ‚Ä¢ Stage:     ensemble\n",
      "   ‚Ä¢ ROC-AUC:   0.9999\n",
      "   ‚Ä¢ F1-Score:  0.9860\n",
      "\n",
      "üîó MLflow:\n",
      "   ‚Ä¢ Tracking URI: ./mlruns\n",
      "   ‚Ä¢ Experiment:   churn_prediction\n",
      "   ‚Ä¢ Runs totales: 12\n",
      "\n",
      "üì¶ Model Registry:\n",
      "   ‚Ä¢ Nom:     Best_Churn_Stacking_LR\n",
      "   ‚Ä¢ Version: 1.0.0\n",
      "   ‚Ä¢ Stage:   production\n",
      "   ‚Ä¢ Path:    processors\\model_registry\\Best_Churn_Stacking_LR\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Pipeline MLflow termin√© avec succ√®s!\n",
      "================================================================================\n",
      "\n",
      "üí° Prochaines √©tapes:\n",
      "   1. Consultez MLflow UI pour voir toutes les runs\n",
      "   2. Chargez le mod√®le avec: load_from_registry()\n",
      "   3. D√©ployez en production\n",
      "   4. Configurez le monitoring\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ R√âSUM√â FINAL - MLflow Tracking\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Mod√®les entra√Æn√©s:\")\n",
    "print(f\"   ‚Ä¢ Baseline:  5 mod√®les\")\n",
    "print(f\"   ‚Ä¢ Tuned:     5 mod√®les (n_iter={N_ITER})\")\n",
    "print(f\"   ‚Ä¢ Ensemble:  2 mod√®les (Stacking + Voting)\")\n",
    "print(f\"   ‚Ä¢ TOTAL:     12 mod√®les\")\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le:\")\n",
    "print(f\"   ‚Ä¢ Nom:       {best_model_name}\")\n",
    "print(f\"   ‚Ä¢ Stage:     {best_stage}\")\n",
    "print(f\"   ‚Ä¢ ROC-AUC:   {best_roc_auc:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {best_row['f1_score']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîó MLflow:\")\n",
    "print(f\"   ‚Ä¢ Tracking URI: {MLFLOW_TRACKING_URI}\")\n",
    "print(f\"   ‚Ä¢ Experiment:   {EXPERIMENT_NAME}\")\n",
    "print(f\"   ‚Ä¢ Runs totales: {len(df_results)}\")\n",
    "\n",
    "print(f\"\\nüì¶ Model Registry:\")\n",
    "print(f\"   ‚Ä¢ Nom:     {registry_name}\")\n",
    "print(f\"   ‚Ä¢ Version: 1.0.0\")\n",
    "print(f\"   ‚Ä¢ Stage:   production\")\n",
    "print(f\"   ‚Ä¢ Path:    {MODEL_REGISTRY_DIR / registry_name.replace(' ', '_')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Pipeline MLflow termin√© avec succ√®s!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüí° Prochaines √©tapes:\")\n",
    "print(\"   1. Consultez MLflow UI pour voir toutes les runs\")\n",
    "print(\"   2. Chargez le mod√®le avec: load_from_registry()\")\n",
    "print(\"   3. D√©ployez en production\")\n",
    "print(\"   4. Configurez le monitoring\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
