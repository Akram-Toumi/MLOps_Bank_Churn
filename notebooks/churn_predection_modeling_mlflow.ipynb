{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ad2ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports standards\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Machine Learning - ModÃ¨les\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Machine Learning - Optimisation\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Machine Learning - Ã‰valuation\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f744d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MLFLOW INTEGRATION FUNCTIONS (FIXED)\n",
    "# ============================================================\n",
    "\n",
    "def setup_mlflow(experiment_name=\"Churn_Prediction_Pipeline\", tracking_uri=None):\n",
    "    \"\"\"\n",
    "    Configure MLflow experiment and tracking\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸš€ CONFIGURATION MLFLOW\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Set tracking URI - IMPORTANT: Must be absolute path or URI\n",
    "    if tracking_uri:\n",
    "        mlflow.set_tracking_uri(tracking_uri)\n",
    "        print(f\"ğŸ“ Tracking URI: {tracking_uri}\")\n",
    "    else:\n",
    "        # Use absolute path for local tracking\n",
    "        mlruns_path = os.path.abspath(\"./mlruns\")\n",
    "        mlflow.set_tracking_uri(f\"file://{mlruns_path}\")\n",
    "        print(f\"ğŸ“ Tracking URI: file://{mlruns_path}\")\n",
    "    \n",
    "    # Set or create experiment\n",
    "    try:\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            experiment_id = mlflow.create_experiment(\n",
    "                experiment_name,\n",
    "                tags={\n",
    "                    \"project\": \"Customer Churn Prediction\",\n",
    "                    \"team\": \"Data Science\",\n",
    "                    \"created_at\": datetime.now().isoformat()\n",
    "                }\n",
    "            )\n",
    "            experiment = mlflow.get_experiment(experiment_id)\n",
    "            print(f\"âœ… Nouvelle expÃ©rience crÃ©Ã©e: {experiment_name}\")\n",
    "        else:\n",
    "            mlflow.set_experiment(experiment_name)\n",
    "            print(f\"âœ… ExpÃ©rience existante: {experiment_name}\")\n",
    "        \n",
    "        print(f\"   â€¢ Experiment ID: {experiment.experiment_id}\")\n",
    "        print(f\"   â€¢ Artifact Location: {experiment.artifact_location}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Erreur lors de la configuration: {str(e)}\")\n",
    "        print(f\"   CrÃ©ation d'une nouvelle expÃ©rience...\")\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "        experiment = mlflow.get_experiment(experiment_id)\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ğŸ“Œ POUR VISUALISER LES RÃ‰SULTATS:\")\n",
    "    print(f\"   ExÃ©cutez: mlflow ui --backend-store-uri {mlflow.get_tracking_uri()}\")\n",
    "    print(f\"   Puis ouvrez: http://localhost:5000\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8a83a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ CONFIGURATION MLFLOW\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Tracking URI: file://c:\\Users\\AkramT\\Desktop\\3eme_s1\\projet_MLOps\\notebooks\\mlruns\n",
      "âš ï¸  Erreur lors de la configuration: file://c:\\Users\\AkramT\\Desktop\\3eme_s1\\projet_MLOps\\notebooks\\mlruns is not a valid remote uri. For remote access on windows, please consider using a different scheme such as SMB (e.g. smb://<hostname>/<path>).\n",
      "   CrÃ©ation d'une nouvelle expÃ©rience...\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "file://c:\\Users\\AkramT\\Desktop\\3eme_s1\\projet_MLOps\\notebooks\\mlruns is not a valid remote uri. For remote access on windows, please consider using a different scheme such as SMB (e.g. smb://<hostname>/<path>).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36msetup_mlflow\u001b[39m\u001b[34m(experiment_name, tracking_uri)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     experiment = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:1678\u001b[39m, in \u001b[36mget_experiment_by_name\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   1645\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1646\u001b[39m \u001b[33;03mRetrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[32m   1647\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1676\u001b[39m \u001b[33;03m    Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[32m   1677\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1678\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.get_experiment_by_name(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\client.py:134\u001b[39m, in \u001b[36mMlflowClient.__init__\u001b[39m\u001b[34m(self, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m._registry_uri = registry_utils._resolve_registry_uri(registry_uri, tracking_uri)\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28mself\u001b[39m._tracking_client = \u001b[43mTrackingServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_tracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:83\u001b[39m, in \u001b[36mTrackingServiceClient.__init__\u001b[39m\u001b[34m(self, tracking_uri)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# property method to ensure that the client is serializable, even if the store is not\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# self.store\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:87\u001b[39m, in \u001b[36mTrackingServiceClient.store\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:208\u001b[39m, in \u001b[36m_get_store\u001b[39m\u001b[34m(store_uri, artifact_uri)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_store\u001b[39m(store_uri=\u001b[38;5;28;01mNone\u001b[39;00m, artifact_uri=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tracking_store_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:45\u001b[39m, in \u001b[36mTrackingStoreRegistry.get_store\u001b[39m\u001b[34m(self, store_uri, artifact_uri)\u001b[39m\n\u001b[32m     44\u001b[39m resolved_store_uri = utils._resolve_tracking_uri(store_uri)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_store_with_resolved_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:56\u001b[39m, in \u001b[36mTrackingStoreRegistry._get_store_with_resolved_uri\u001b[39m\u001b[34m(self, resolved_store_uri, artifact_uri)\u001b[39m\n\u001b[32m     55\u001b[39m builder = \u001b[38;5;28mself\u001b[39m.get_store_builder(resolved_store_uri)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:132\u001b[39m, in \u001b[36m_get_file_store\u001b[39m\u001b[34m(store_uri, **_)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_file_store\u001b[39m(store_uri, **_):\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:188\u001b[39m, in \u001b[36mFileStore.__init__\u001b[39m\u001b[34m(self, root_directory, artifact_root_uri)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[38;5;28mself\u001b[39m.artifact_root_uri = \u001b[43mresolve_uri_if_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_root_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28mself\u001b[39m.trash_folder = os.path.join(\u001b[38;5;28mself\u001b[39m.root_directory, FileStore.TRASH_FOLDER_NAME)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\utils\\uri.py:427\u001b[39m, in \u001b[36mresolve_uri_if_local\u001b[39m\u001b[34m(local_uri)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m local_file_uri_to_path\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_uri \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mis_local_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_uri\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    428\u001b[39m     scheme = get_uri_scheme(local_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\utils\\uri.py:57\u001b[39m, in \u001b[36mis_local_uri\u001b[39m\u001b[34m(uri, is_tracking_or_registry_uri)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_remote_hostname:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m     58\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid remote uri. For remote access \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     59\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mon windows, please consider using a different scheme \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msuch as SMB (e.g. smb://<hostname>/<path>).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m     )\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mMlflowException\u001b[39m: file://c:\\Users\\AkramT\\Desktop\\3eme_s1\\projet_MLOps\\notebooks\\mlruns is not a valid remote uri. For remote access on windows, please consider using a different scheme such as SMB (e.g. smb://<hostname>/<path>).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m PROCESSOR_DIR = \u001b[33m'\u001b[39m\u001b[33mprocessors\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Setup MLflow\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m mlflow_experiment = \u001b[43msetup_mlflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36msetup_mlflow\u001b[39m\u001b[34m(experiment_name, tracking_uri)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâš ï¸  Erreur lors de la configuration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   CrÃ©ation d\u001b[39m\u001b[33m'\u001b[39m\u001b[33mune nouvelle expÃ©rience...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m experiment_id = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m experiment = mlflow.get_experiment(experiment_id)\n\u001b[32m     49\u001b[39m mlflow.set_experiment(experiment_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:1843\u001b[39m, in \u001b[36mcreate_experiment\u001b[39m\u001b[34m(name, artifact_location, tags)\u001b[39m\n\u001b[32m   1795\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_experiment\u001b[39m(\n\u001b[32m   1796\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   1797\u001b[39m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1798\u001b[39m     tags: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1799\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m   1800\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1801\u001b[39m \u001b[33;03m    Create an experiment.\u001b[39;00m\n\u001b[32m   1802\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1841\u001b[39m \u001b[33;03m        Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[32m   1842\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.create_experiment(name, artifact_location, tags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\client.py:134\u001b[39m, in \u001b[36mMlflowClient.__init__\u001b[39m\u001b[34m(self, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m    132\u001b[39m final_tracking_uri = utils._resolve_tracking_uri(tracking_uri)\n\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m._registry_uri = registry_utils._resolve_registry_uri(registry_uri, tracking_uri)\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28mself\u001b[39m._tracking_client = \u001b[43mTrackingServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_tracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:83\u001b[39m, in \u001b[36mTrackingServiceClient.__init__\u001b[39m\u001b[34m(self, tracking_uri)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m.tracking_uri = tracking_uri\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# property method to ensure that the client is serializable, even if the store is not\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# self.store\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:87\u001b[39m, in \u001b[36mTrackingServiceClient.store\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:208\u001b[39m, in \u001b[36m_get_store\u001b[39m\u001b[34m(store_uri, artifact_uri)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_store\u001b[39m(store_uri=\u001b[38;5;28;01mNone\u001b[39;00m, artifact_uri=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tracking_store_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:45\u001b[39m, in \u001b[36mTrackingStoreRegistry.get_store\u001b[39m\u001b[34m(self, store_uri, artifact_uri)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tracking_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m     44\u001b[39m resolved_store_uri = utils._resolve_tracking_uri(store_uri)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_store_with_resolved_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:56\u001b[39m, in \u001b[36mTrackingStoreRegistry._get_store_with_resolved_uri\u001b[39m\u001b[34m(self, resolved_store_uri, artifact_uri)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _building_store_lock:\n\u001b[32m     55\u001b[39m     builder = \u001b[38;5;28mself\u001b[39m.get_store_builder(resolved_store_uri)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:132\u001b[39m, in \u001b[36m_get_file_store\u001b[39m\u001b[34m(store_uri, **_)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_file_store\u001b[39m(store_uri, **_):\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:188\u001b[39m, in \u001b[36mFileStore.__init__\u001b[39m\u001b[34m(self, root_directory, artifact_root_uri)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28mself\u001b[39m.artifact_root_uri = path_to_local_file_uri(\u001b[38;5;28mself\u001b[39m.root_directory)\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[38;5;28mself\u001b[39m.artifact_root_uri = \u001b[43mresolve_uri_if_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_root_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28mself\u001b[39m.trash_folder = os.path.join(\u001b[38;5;28mself\u001b[39m.root_directory, FileStore.TRASH_FOLDER_NAME)\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# Create root directory if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\utils\\uri.py:427\u001b[39m, in \u001b[36mresolve_uri_if_local\u001b[39m\u001b[34m(local_uri)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[33;03mif `local_uri` is passed in as a relative local path, this function\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03mresolves it to absolute path relative to current working directory.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    423\u001b[39m \u001b[33;03m    a fully-formed absolute uri path or an absolute filesystem path\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m local_file_uri_to_path\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_uri \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mis_local_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_uri\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    428\u001b[39m     scheme = get_uri_scheme(local_uri)\n\u001b[32m    429\u001b[39m     cwd = pathlib.Path.cwd()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\mlflow\\utils\\uri.py:57\u001b[39m, in \u001b[36mis_local_uri\u001b[39m\u001b[34m(uri, is_tracking_or_registry_uri)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scheme == \u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_remote_hostname:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m     58\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid remote uri. For remote access \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     59\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mon windows, please consider using a different scheme \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msuch as SMB (e.g. smb://<hostname>/<path>).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m         )\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_remote_hostname:\n",
      "\u001b[31mMlflowException\u001b[39m: file://c:\\Users\\AkramT\\Desktop\\3eme_s1\\projet_MLOps\\notebooks\\mlruns is not a valid remote uri. For remote access on windows, please consider using a different scheme such as SMB (e.g. smb://<hostname>/<path>)."
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# DÃ©finir le chemin vers les processeurs\n",
    "PROCESSOR_DIR = 'processors'\n",
    "\n",
    "# Setup MLflow\n",
    "mlflow_experiment = setup_mlflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe81ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHARGEMENT DES DONNÃ‰ES PREPROCESSÃ‰ES\n",
      "================================================================================\n",
      "âœ… DonnÃ©es chargÃ©es:\n",
      "   â€¢ X_train: (42070, 40)\n",
      "   â€¢ X_test:  (6000, 40)\n",
      "   â€¢ y_train: (42070,)\n",
      "   â€¢ y_test:  (6000,)\n",
      "\n",
      "âœ… Processeurs chargÃ©s:\n",
      "   â€¢ scaler.pkl\n",
      "   â€¢ label_encoders.pkl\n",
      "   â€¢ feature_names.pkl\n",
      "   â€¢ smote_config.pkl\n",
      "\n",
      "ğŸ“Š Distribution des classes:\n",
      "   â€¢ Train - Churn: 21,035 (50.00%)\n",
      "   â€¢ Train - Normal: 21,035 (50.00%)\n",
      "   â€¢ Test  - Churn: 741 (12.35%)\n",
      "   â€¢ Test  - Normal: 5,259 (87.65%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. CHARGEMENT DES DONNÃ‰ES\n",
    "# ============================================================\n",
    "\n",
    "def load_preprocessed_data(processor_dir=PROCESSOR_DIR):\n",
    "    \"\"\"\n",
    "    Charge les donnÃ©es preprocessÃ©es et les processeurs\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"CHARGEMENT DES DONNÃ‰ES PREPROCESSÃ‰ES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Charger les donnÃ©es\n",
    "    data_path = os.path.join(processor_dir, 'preprocessed_data.pkl')\n",
    "    with open(data_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    X_train = data['X_train']\n",
    "    X_test = data['X_test']\n",
    "    y_train = data['y_train']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    print(f\"âœ… DonnÃ©es chargÃ©es:\")\n",
    "    print(f\"   â€¢ X_train: {X_train.shape}\")\n",
    "    print(f\"   â€¢ X_test:  {X_test.shape}\")\n",
    "    print(f\"   â€¢ y_train: {y_train.shape}\")\n",
    "    print(f\"   â€¢ y_test:  {y_test.shape}\")\n",
    "    \n",
    "    # Charger les processeurs\n",
    "    processors = {}\n",
    "    processor_files = ['scaler.pkl', 'label_encoders.pkl', 'feature_names.pkl', 'smote_config.pkl']\n",
    "    \n",
    "    print(f\"\\nâœ… Processeurs chargÃ©s:\")\n",
    "    for filename in processor_files:\n",
    "        filepath = os.path.join(processor_dir, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                processors[filename.replace('.pkl', '')] = pickle.load(f)\n",
    "            print(f\"   â€¢ {filename}\")\n",
    "    \n",
    "    # Statistiques sur les classes\n",
    "    print(f\"\\nğŸ“Š Distribution des classes:\")\n",
    "    print(f\"   â€¢ Train - Churn: {y_train.sum():,} ({y_train.mean()*100:.2f}%)\")\n",
    "    print(f\"   â€¢ Train - Normal: {(~y_train.astype(bool)).sum():,} ({(1-y_train.mean())*100:.2f}%)\")\n",
    "    print(f\"   â€¢ Test  - Churn: {y_test.sum():,} ({y_test.mean()*100:.2f}%)\")\n",
    "    print(f\"   â€¢ Test  - Normal: {(~y_test.astype(bool)).sum():,} ({(1-y_test.mean())*100:.2f}%)\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, processors\n",
    "\n",
    "\n",
    "# Charger les donnÃ©es\n",
    "X_train, X_test, y_train, y_test, processors = load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62fb041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ INITIALISATION DES MODÃˆLES BASELINE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Ratio de dÃ©sÃ©quilibre calculÃ©: 1.00\n",
      "   â†’ Sera utilisÃ© pour pondÃ©rer les classes\n",
      "\n",
      "âœ… ModÃ¨les configurÃ©s:\n",
      "\n",
      "   1. XGBoost\n",
      "      â””â”€ Estimateurs: 150\n",
      "   2. LightGBM\n",
      "      â””â”€ Estimateurs: 150\n",
      "   3. Random Forest\n",
      "      â””â”€ Estimateurs: 200\n",
      "   4. CatBoost\n",
      "   5. Logistic Regression (ElasticNet)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. INITIALISATION DES MODÃˆLES BASELINE\n",
    "# ============================================================\n",
    "\n",
    "def initialize_baseline_models():\n",
    "    \"\"\"\n",
    "    Initialise les modÃ¨les de base\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸš€ INITIALISATION DES MODÃˆLES BASELINE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    fraud_ratio = y_train.sum() / len(y_train)\n",
    "    scale_pos = (1 - fraud_ratio) / fraud_ratio\n",
    "    \n",
    "    print(f\"ğŸ“Š Ratio de dÃ©sÃ©quilibre calculÃ©: {scale_pos:.2f}\")\n",
    "    print(f\"   â†’ Sera utilisÃ© pour pondÃ©rer les classes\\n\")\n",
    "    \n",
    "    baseline_config = {\n",
    "        'XGBoost': XGBClassifier(\n",
    "            n_estimators=150,\n",
    "            max_depth=7,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            min_child_weight=3,\n",
    "            gamma=0.1,\n",
    "            scale_pos_weight=scale_pos,\n",
    "            random_state=42,\n",
    "            eval_metric='auc',\n",
    "            use_label_encoder=False,\n",
    "            tree_method='hist'\n",
    "        ),\n",
    "        \n",
    "        'LightGBM': LGBMClassifier(\n",
    "            n_estimators=150,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=40,\n",
    "            min_child_samples=25,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1,\n",
    "            importance_type='gain'\n",
    "        ),\n",
    "        \n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=25,\n",
    "            min_samples_split=15,\n",
    "            min_samples_leaf=5,\n",
    "            max_features='sqrt',\n",
    "            class_weight='balanced_subsample',\n",
    "            bootstrap=True,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            warm_start=False\n",
    "        ),\n",
    "        \n",
    "        'CatBoost': CatBoostClassifier(\n",
    "            iterations=150,\n",
    "            depth=7,\n",
    "            learning_rate=0.05,\n",
    "            l2_leaf_reg=3,\n",
    "            border_count=128,\n",
    "            auto_class_weights='Balanced',\n",
    "            random_state=42,\n",
    "            verbose=False,\n",
    "            task_type='CPU',\n",
    "            bootstrap_type='Bernoulli',\n",
    "            subsample=0.85\n",
    "        ),\n",
    "        \n",
    "        'Logistic Regression (ElasticNet)': LogisticRegression(\n",
    "            penalty='elasticnet',\n",
    "            C=1.0,\n",
    "            l1_ratio=0.5,\n",
    "            solver='saga',\n",
    "            max_iter=1000,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            warm_start=False\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    print(\"âœ… ModÃ¨les configurÃ©s:\\n\")\n",
    "    for idx, (model_name, model) in enumerate(baseline_config.items(), 1):\n",
    "        print(f\"   {idx}. {model_name}\")\n",
    "        if hasattr(model, 'n_estimators'):\n",
    "            print(f\"      â””â”€ Estimateurs: {model.n_estimators}\")\n",
    "        elif hasattr(model, 'iterations'):\n",
    "            print(f\"      â””â”€ ItÃ©rations: {model.iterations}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "    return baseline_config\n",
    "\n",
    "\n",
    "baseline_models = initialize_baseline_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320db9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¯ ENTRAÃNEMENT BASELINE AVEC MLFLOW\n",
      "================================================================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ [1/5] XGBoost                                                            â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'XGBoost_Baseline'.\n",
      "Created version '1' of model 'XGBoost_Baseline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ“ ROC-AUC: 0.9995\n",
      "   âœ“ F1-Score: 0.9640\n",
      "   âœ“ Temps: 2.55s\n",
      "   âœ“ Run ID: 89dc50c1541c4d9e96d1b390cc4c95a3\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ [2/5] LightGBM                                                           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'LightGBM_Baseline'.\n",
      "Created version '1' of model 'LightGBM_Baseline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ“ ROC-AUC: 0.9995\n",
      "   âœ“ F1-Score: 0.9667\n",
      "   âœ“ Temps: 2.00s\n",
      "   âœ“ Run ID: 06f65f885ef54462a91c234ece686132\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ [3/5] Random Forest                                                      â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Random Forest_Baseline'.\n",
      "Created version '1' of model 'Random Forest_Baseline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ“ ROC-AUC: 0.9971\n",
      "   âœ“ F1-Score: 0.9174\n",
      "   âœ“ Temps: 6.59s\n",
      "   âœ“ Run ID: 33bfb294c2de48eb9df4ad00eed83b4d\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ [4/5] CatBoost                                                           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'CatBoost_Baseline'.\n",
      "Created version '1' of model 'CatBoost_Baseline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ“ ROC-AUC: 0.9998\n",
      "   âœ“ F1-Score: 0.9715\n",
      "   âœ“ Temps: 4.17s\n",
      "   âœ“ Run ID: c73db1c4178e4d98a5522be9d4cb47cc\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ [5/5] Logistic Regression (ElasticNet)                                   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Logistic Regression (ElasticNet)_Baseline'.\n",
      "Created version '1' of model 'Logistic Regression (ElasticNet)_Baseline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ“ ROC-AUC: 0.9998\n",
      "   âœ“ F1-Score: 0.9488\n",
      "   âœ“ Temps: 35.18s\n",
      "   âœ“ Run ID: 9ef6019518f24c5c96b6fa2b1bc58823\n",
      "\n",
      "================================================================================\n",
      "âœ… BASELINE TERMINÃ‰ - 5/5 modÃ¨les\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. ENTRAÃNEMENT DES MODÃˆLES BASELINE AVEC MLFLOW \n",
    "# ============================================================\n",
    "\n",
    "def train_baseline_models_with_mlflow(models_dict, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    EntraÃ®ne les modÃ¨les baseline avec tracking MLflow\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸ¯ ENTRAÃNEMENT BASELINE AVEC MLFLOW\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    performance_tracker = {}\n",
    "    \n",
    "    for model_idx, (model_name, model_instance) in enumerate(models_dict.items(), 1):\n",
    "        print(f\"â”Œ{'â”€'*78}â”\")\n",
    "        print(f\"â”‚ [{model_idx}/{len(models_dict)}] {model_name:<66} â”‚\")\n",
    "        print(f\"â””{'â”€'*78}â”˜\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"{model_name}_baseline\") as run:\n",
    "            start = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Log des paramÃ¨tres\n",
    "                mlflow.log_param(\"model_type\", type(model_instance).__name__)\n",
    "                mlflow.log_param(\"model_category\", \"Baseline\")\n",
    "                mlflow.log_param(\"training_samples\", len(X_train))\n",
    "                mlflow.log_param(\"test_samples\", len(X_test))\n",
    "                \n",
    "                # Log des hyperparamÃ¨tres\n",
    "                model_params = model_instance.get_params()\n",
    "                for param_name, param_value in model_params.items():\n",
    "                    if param_value is not None and not callable(param_value):\n",
    "                        try:\n",
    "                            mlflow.log_param(f\"hp_{param_name}\", str(param_value)[:250])\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                # EntraÃ®nement\n",
    "                print(f\"   ğŸ”„ EntraÃ®nement en cours...\")\n",
    "                model_instance.fit(X_train, y_train)\n",
    "                train_duration = time.time() - start\n",
    "                \n",
    "                # PrÃ©dictions\n",
    "                predictions = model_instance.predict(X_test)\n",
    "                predictions_proba = model_instance.predict_proba(X_test)[:, 1]\n",
    "                \n",
    "                # Calcul des mÃ©triques\n",
    "                metrics = {\n",
    "                    'model_object': model_instance,\n",
    "                    'accuracy': accuracy_score(y_test, predictions),\n",
    "                    'precision': precision_score(y_test, predictions, zero_division=0),\n",
    "                    'recall': recall_score(y_test, predictions, zero_division=0),\n",
    "                    'f1_score': f1_score(y_test, predictions, zero_division=0),\n",
    "                    'roc_auc': roc_auc_score(y_test, predictions_proba),\n",
    "                    'train_time_seconds': train_duration,\n",
    "                    'predictions': predictions,\n",
    "                    'predictions_proba': predictions_proba,\n",
    "                    'confusion_matrix': confusion_matrix(y_test, predictions),\n",
    "                    'run_id': run.info.run_id\n",
    "                }\n",
    "                \n",
    "                performance_tracker[model_name] = metrics\n",
    "                \n",
    "                # Log des mÃ©triques\n",
    "                mlflow.log_metric(\"accuracy\", metrics['accuracy'])\n",
    "                mlflow.log_metric(\"precision\", metrics['precision'])\n",
    "                mlflow.log_metric(\"recall\", metrics['recall'])\n",
    "                mlflow.log_metric(\"f1_score\", metrics['f1_score'])\n",
    "                mlflow.log_metric(\"roc_auc\", metrics['roc_auc'])\n",
    "                mlflow.log_metric(\"training_time\", train_duration)\n",
    "                \n",
    "                # Log matrice de confusion\n",
    "                tn, fp, fn, tp = metrics['confusion_matrix'].ravel()\n",
    "                mlflow.log_metric(\"true_negatives\", int(tn))\n",
    "                mlflow.log_metric(\"false_positives\", int(fp))\n",
    "                mlflow.log_metric(\"false_negatives\", int(fn))\n",
    "                mlflow.log_metric(\"true_positives\", int(tp))\n",
    "                \n",
    "                # Log du modÃ¨le avec signature\n",
    "                try:\n",
    "                    signature = infer_signature(X_train, predictions_proba)\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        model_instance,\n",
    "                        artifact_path=\"model\",\n",
    "                        signature=signature\n",
    "                    )\n",
    "                    # Register model separately\n",
    "                    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "                    mlflow.register_model(model_uri, f\"{model_name.replace(' ', '_')}_Baseline\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   âš ï¸  Avertissement lors du log du modÃ¨le: {str(e)}\")\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        model_instance,\n",
    "                        artifact_path=\"model\"\n",
    "                    )\n",
    "                \n",
    "                # Graphique ROC\n",
    "                fig, ax = plt.subplots(figsize=(8, 6))\n",
    "                fpr, tpr, _ = roc_curve(y_test, predictions_proba)\n",
    "                ax.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {metrics[\"roc_auc\"]:.3f})')\n",
    "                ax.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "                ax.set_xlabel('False Positive Rate')\n",
    "                ax.set_ylabel('True Positive Rate')\n",
    "                ax.set_title(f'ROC Curve - {model_name}')\n",
    "                ax.legend()\n",
    "                ax.grid(alpha=0.3)\n",
    "                \n",
    "                roc_path = f\"roc_curve_{model_name.replace(' ', '_')}_baseline.png\"\n",
    "                plt.savefig(roc_path, dpi=150, bbox_inches='tight')\n",
    "                mlflow.log_artifact(roc_path)\n",
    "                plt.close()\n",
    "                if os.path.exists(roc_path):\n",
    "                    os.remove(roc_path)\n",
    "                \n",
    "                print(f\"   âœ“ ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "                print(f\"   âœ“ F1-Score: {metrics['f1_score']:.4f}\")\n",
    "                print(f\"   âœ“ Temps: {train_duration:.2f}s\")\n",
    "                print(f\"   âœ“ Run ID: {run.info.run_id}\")\n",
    "                print()\n",
    "                \n",
    "                mlflow.set_tag(\"stage\", \"baseline\")\n",
    "                mlflow.set_tag(\"model_name\", model_name)\n",
    "                mlflow.set_tag(\"status\", \"success\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Erreur: {str(e)}\\n\")\n",
    "                mlflow.log_param(\"status\", \"failed\")\n",
    "                mlflow.log_param(\"error\", str(e))\n",
    "                mlflow.set_tag(\"status\", \"failed\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"âœ… BASELINE TERMINÃ‰ - {len(performance_tracker)}/{len(models_dict)} modÃ¨les\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return performance_tracker\n",
    "\n",
    "\n",
    "baseline_results = train_baseline_models_with_mlflow(\n",
    "    baseline_models, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test, \n",
    "    y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“‹ CONFIGURATION DES ESPACES DE RECHERCHE\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ XGBoost\n",
      "   â””â”€ Nombre d'hyperparamÃ¨tres: 9\n",
      "\n",
      "ğŸ¯ LightGBM\n",
      "   â””â”€ Nombre d'hyperparamÃ¨tres: 10\n",
      "\n",
      "ğŸ¯ Random Forest\n",
      "   â””â”€ Nombre d'hyperparamÃ¨tres: 7\n",
      "\n",
      "ğŸ¯ CatBoost\n",
      "   â””â”€ Nombre d'hyperparamÃ¨tres: 7\n",
      "\n",
      "ğŸ¯ Logistic Regression (ElasticNet)\n",
      "   â””â”€ Nombre d'hyperparamÃ¨tres: 4\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. DÃ‰FINITION DES HYPERPARAMÃˆTRES\n",
    "# ============================================================\n",
    "\n",
    "def define_hyperparameter_search_space():\n",
    "    \"\"\"\n",
    "    DÃ©finit les espaces de recherche pour l'optimisation\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸ“‹ CONFIGURATION DES ESPACES DE RECHERCHE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    search_spaces = {\n",
    "        'XGBoost': {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'max_depth': randint(3, 12),\n",
    "            'learning_rate': uniform(0.01, 0.29),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4),\n",
    "            'gamma': uniform(0, 0.5),\n",
    "            'min_child_weight': randint(1, 10),\n",
    "            'reg_alpha': uniform(0, 1),\n",
    "            'reg_lambda': uniform(0, 2)\n",
    "        },\n",
    "        \n",
    "        'LightGBM': {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'max_depth': randint(-1, 15),\n",
    "            'learning_rate': uniform(0.01, 0.29),\n",
    "            'num_leaves': randint(15, 150),\n",
    "            'min_child_samples': randint(10, 60),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4),\n",
    "            'reg_alpha': uniform(0, 1),\n",
    "            'reg_lambda': uniform(0, 2),\n",
    "            'min_split_gain': uniform(0, 0.1)\n",
    "        },\n",
    "        \n",
    "        'Random Forest': {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'max_depth': [15, 20, 25, 30, 35, None],\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': ['sqrt', 'log2', 0.5, 0.7, 0.9],\n",
    "            'max_samples': uniform(0.7, 0.3),\n",
    "            'class_weight': ['balanced', 'balanced_subsample']\n",
    "        },\n",
    "        \n",
    "        'CatBoost': {\n",
    "            'iterations': randint(100, 500),\n",
    "            'depth': randint(4, 11),\n",
    "            'learning_rate': uniform(0.01, 0.29),\n",
    "            'l2_leaf_reg': uniform(1, 9),\n",
    "            'border_count': [32, 64, 128, 200, 254],\n",
    "            'bagging_temperature': uniform(0, 1),\n",
    "            'random_strength': uniform(0, 2)\n",
    "        },\n",
    "        \n",
    "        'Logistic Regression (ElasticNet)': {\n",
    "            'C': uniform(0.001, 10),\n",
    "            'l1_ratio': uniform(0, 1),\n",
    "            'max_iter': randint(500, 2000),\n",
    "            'tol': uniform(1e-5, 1e-3)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for model_name, params in search_spaces.items():\n",
    "        param_count = len(params)\n",
    "        print(f\"ğŸ¯ {model_name}\")\n",
    "        print(f\"   â””â”€ Nombre d'hyperparamÃ¨tres: {param_count}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "    return search_spaces\n",
    "\n",
    "\n",
    "hyperparameter_spaces = define_hyperparameter_search_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b19a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ OPTIMISATION AVEC MLFLOW\n",
      "================================================================================\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [1/5] XGBoost                                                            â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   ğŸ” Optimisation en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'XGBoost_Optimized'.\n",
      "Created version '1' of model 'XGBoost_Optimized'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Best CV Score: nan\n",
      "   âœ… Temps: 76.15s\n",
      "   âœ… Run ID: 1406d17bb39d46209b484786c723ba46\n",
      "   ğŸ“ˆ AmÃ©lioration: +nan%\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [2/5] LightGBM                                                           â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   ğŸ” Optimisation en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'LightGBM_Optimized'.\n",
      "Created version '1' of model 'LightGBM_Optimized'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Best CV Score: 0.9999\n",
      "   âœ… Temps: 70.37s\n",
      "   âœ… Run ID: 6aed045a5fb147ffbf85c96385dfa6cb\n",
      "   ğŸ“ˆ AmÃ©lioration: +0.04%\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [3/5] Random Forest                                                      â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   ğŸ” Optimisation en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Random Forest_Optimized'.\n",
      "Created version '1' of model 'Random Forest_Optimized'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Best CV Score: 0.9997\n",
      "   âœ… Temps: 800.24s\n",
      "   âœ… Run ID: a2d98b39527f42979081613e230c0599\n",
      "   ğŸ“ˆ AmÃ©lioration: +0.26%\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [4/5] CatBoost                                                           â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   ğŸ” Optimisation en cours...\n",
      "   âŒ Erreur: \n",
      "All the 75 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\catboost\\core.py\", line 2395, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AkramT\\anaconda3\\envs\\mlops\\Lib\\site-packages\\catboost\\core.py\", line 2321, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:44: Error: bagging temperature available for bayesian bootstrap only\n",
      "\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [5/5] Logistic Regression (ElasticNet)                                   â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   ğŸ” Optimisation en cours...\n",
      "   âœ… Best CV Score: 1.0000\n",
      "   âœ… Temps: 435.33s\n",
      "   âœ… Run ID: 74d850b9c58e4ab1ae9ef6ee0304f2d8\n",
      "   ğŸ“ˆ AmÃ©lioration: +0.02%\n",
      "\n",
      "================================================================================\n",
      "âœ… OPTIMISATION TERMINÃ‰E\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Logistic Regression (ElasticNet)_Optimized'.\n",
      "Created version '1' of model 'Logistic Regression (ElasticNet)_Optimized'.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5. OPTIMISATION AVEC MLFLOW \n",
    "# ============================================================\n",
    "\n",
    "def optimize_models_with_mlflow(\n",
    "    base_models, \n",
    "    search_spaces, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    n_iterations=25, \n",
    "    cv_folds=3,\n",
    "    scoring_metric='roc_auc'\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimise les hyperparamÃ¨tres avec tracking MLflow\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸš€ OPTIMISATION AVEC MLFLOW\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    optimized_models = {}\n",
    "    optimization_results = {}\n",
    "    \n",
    "    for idx, (model_name, base_estimator) in enumerate(base_models.items(), 1):\n",
    "        print(f\"â•”{'â•'*78}â•—\")\n",
    "        print(f\"â•‘ [{idx}/{len(base_models)}] {model_name:<66} â•‘\")\n",
    "        print(f\"â•š{'â•'*78}â•\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"{model_name}_optimization\") as parent_run:\n",
    "            model_start = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Log des paramÃ¨tres\n",
    "                mlflow.log_param(\"model_type\", type(base_estimator).__name__)\n",
    "                mlflow.log_param(\"model_category\", \"Optimization\")\n",
    "                mlflow.log_param(\"n_iterations\", n_iterations)\n",
    "                mlflow.log_param(\"cv_folds\", cv_folds)\n",
    "                mlflow.log_param(\"scoring_metric\", scoring_metric)\n",
    "                \n",
    "                # RandomizedSearchCV\n",
    "                randomized_optimizer = RandomizedSearchCV(\n",
    "                    estimator=base_estimator,\n",
    "                    param_distributions=search_spaces[model_name],\n",
    "                    n_iter=n_iterations,\n",
    "                    cv=cv_folds,\n",
    "                    scoring=scoring_metric,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=42,\n",
    "                    verbose=0,\n",
    "                    return_train_score=True\n",
    "                )\n",
    "                \n",
    "                print(f\"   ğŸ” Optimisation en cours...\")\n",
    "                randomized_optimizer.fit(X_train, y_train)\n",
    "                \n",
    "                optimization_time = time.time() - model_start\n",
    "                \n",
    "                # Sauvegarder\n",
    "                optimized_models[model_name] = randomized_optimizer.best_estimator_\n",
    "                \n",
    "                optimization_results[model_name] = {\n",
    "                    'best_params': randomized_optimizer.best_params_,\n",
    "                    'best_cv_score': randomized_optimizer.best_score_,\n",
    "                    'optimization_time': optimization_time,\n",
    "                    'run_id': parent_run.info.run_id\n",
    "                }\n",
    "                \n",
    "                # Log\n",
    "                mlflow.log_metric(\"best_cv_score\", randomized_optimizer.best_score_)\n",
    "                mlflow.log_metric(\"optimization_time\", optimization_time)\n",
    "                \n",
    "                for param_key, param_val in randomized_optimizer.best_params_.items():\n",
    "                    try:\n",
    "                        mlflow.log_param(f\"best_{param_key}\", str(param_val)[:250])\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # Log du modÃ¨le\n",
    "                try:\n",
    "                    signature = infer_signature(X_train, randomized_optimizer.predict_proba(X_train)[:, 1])\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        randomized_optimizer.best_estimator_,\n",
    "                        artifact_path=\"optimized_model\",\n",
    "                        signature=signature\n",
    "                    )\n",
    "                    # Register model\n",
    "                    model_uri = f\"runs:/{parent_run.info.run_id}/optimized_model\"\n",
    "                    mlflow.register_model(model_uri, f\"{model_name.replace(' ', '_')}_Optimized\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   âš ï¸  Avertissement lors du log du modÃ¨le: {str(e)}\")\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        randomized_optimizer.best_estimator_,\n",
    "                        artifact_path=\"optimized_model\"\n",
    "                    )\n",
    "                \n",
    "                print(f\"   âœ… Best CV Score: {randomized_optimizer.best_score_:.4f}\")\n",
    "                print(f\"   âœ… Temps: {optimization_time:.2f}s\")\n",
    "                print(f\"   âœ… Run ID: {parent_run.info.run_id}\")\n",
    "                \n",
    "                if model_name in baseline_results:\n",
    "                    baseline_score = baseline_results[model_name]['roc_auc']\n",
    "                    improvement = (randomized_optimizer.best_score_ - baseline_score) * 100\n",
    "                    mlflow.log_metric(\"improvement_vs_baseline\", improvement)\n",
    "                    print(f\"   ğŸ“ˆ AmÃ©lioration: {improvement:+.2f}%\")\n",
    "                \n",
    "                print()\n",
    "                \n",
    "                mlflow.set_tag(\"stage\", \"optimization\")\n",
    "                mlflow.set_tag(\"model_name\", model_name)\n",
    "                mlflow.set_tag(\"status\", \"success\")\n",
    "                \n",
    "            except Exception as error:\n",
    "                print(f\"   âŒ Erreur: {str(error)}\\n\")\n",
    "                mlflow.log_param(\"status\", \"failed\")\n",
    "                mlflow.log_param(\"error\", str(error))\n",
    "                mlflow.set_tag(\"status\", \"failed\")\n",
    "                optimized_models[model_name] = base_estimator\n",
    "                continue\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"âœ… OPTIMISATION TERMINÃ‰E\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return optimized_models, optimization_results\n",
    "\n",
    "\n",
    "optimized_models, tuning_results = optimize_models_with_mlflow(\n",
    "    base_models=baseline_models,\n",
    "    search_spaces=hyperparameter_spaces,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    n_iterations=25,\n",
    "    cv_folds=3,\n",
    "    scoring_metric='roc_auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd86497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“Š Ã‰VALUATION AVEC MLFLOW\n",
      "================================================================================\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [1/5] XGBoost                                                    â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   âœ“ ROC-AUC: 0.9997\n",
      "   âœ“ F1-Score: 0.9737\n",
      "   âœ“ Run ID: 80ba6f831ddc4b8bbfa029eacb8945cd\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [2/5] LightGBM                                                   â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   âœ“ ROC-AUC: 0.9997\n",
      "   âœ“ F1-Score: 0.9724\n",
      "   âœ“ Run ID: 880d74172cd441ba9e3ab1b8a704f1d6\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [3/5] Random Forest                                              â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   âœ“ ROC-AUC: 0.9975\n",
      "   âœ“ F1-Score: 0.9173\n",
      "   âœ“ Run ID: e1c8a7717c09446db67ac601811fcf23\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [4/5] CatBoost                                                   â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   âœ“ ROC-AUC: 0.9998\n",
      "   âœ“ F1-Score: 0.9715\n",
      "   âœ“ Run ID: 66987bc9a881497e9f24062dfd3c4ee2\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [5/5] Logistic Regression (ElasticNet)                           â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   âœ“ ROC-AUC: 0.9999\n",
      "   âœ“ F1-Score: 0.9549\n",
      "   âœ“ Run ID: 8dd3818ec9e04c548083f1d4526e996a\n",
      "\n",
      "================================================================================\n",
      "âœ… Ã‰VALUATION TERMINÃ‰E\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. Ã‰VALUATION DES MODÃˆLES OPTIMISÃ‰S\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_optimized_models_with_mlflow(optimized_models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Ã‰value les modÃ¨les optimisÃ©s avec tracking MLflow\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸ“Š Ã‰VALUATION AVEC MLFLOW\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    optimized_performance = {}\n",
    "    \n",
    "    for model_idx, (model_name, optimized_model) in enumerate(optimized_models.items(), 1):\n",
    "        print(f\"â•”{'â•'*78}â•—\")\n",
    "        print(f\"â•‘ [{model_idx}/{len(optimized_models)}] {model_name:<58} â•‘\")\n",
    "        print(f\"â•š{'â•'*78}â•\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"{model_name}_evaluation\") as run:\n",
    "            eval_start = time.time()\n",
    "            \n",
    "            try:\n",
    "                # PrÃ©dictions\n",
    "                test_predictions = optimized_model.predict(X_test)\n",
    "                test_probabilities = optimized_model.predict_proba(X_test)[:, 1]\n",
    "                \n",
    "                # MÃ©triques\n",
    "                performance_metrics = {\n",
    "                    'model_instance': optimized_model,\n",
    "                    'accuracy': accuracy_score(y_test, test_predictions),\n",
    "                    'precision': precision_score(y_test, test_predictions, zero_division=0),\n",
    "                    'recall': recall_score(y_test, test_predictions, zero_division=0),\n",
    "                    'f1_score': f1_score(y_test, test_predictions, zero_division=0),\n",
    "                    'roc_auc': roc_auc_score(y_test, test_probabilities),\n",
    "                    'eval_time': time.time() - eval_start,\n",
    "                    'test_predictions': test_predictions,\n",
    "                    'test_probabilities': test_probabilities,\n",
    "                    'confusion_mat': confusion_matrix(y_test, test_predictions),\n",
    "                    'run_id': run.info.run_id\n",
    "                }\n",
    "                \n",
    "                optimized_performance[model_name] = performance_metrics\n",
    "                \n",
    "                # Log\n",
    "                mlflow.log_param(\"model_type\", type(optimized_model).__name__)\n",
    "                mlflow.log_param(\"model_category\", \"Optimized_Evaluation\")\n",
    "                \n",
    "                mlflow.log_metric(\"accuracy\", performance_metrics['accuracy'])\n",
    "                mlflow.log_metric(\"precision\", performance_metrics['precision'])\n",
    "                mlflow.log_metric(\"recall\", performance_metrics['recall'])\n",
    "                mlflow.log_metric(\"f1_score\", performance_metrics['f1_score'])\n",
    "                mlflow.log_metric(\"roc_auc\", performance_metrics['roc_auc'])\n",
    "                \n",
    "                tn, fp, fn, tp = performance_metrics['confusion_mat'].ravel()\n",
    "                mlflow.log_metric(\"true_negatives\", int(tn))\n",
    "                mlflow.log_metric(\"false_positives\", int(fp))\n",
    "                mlflow.log_metric(\"false_negatives\", int(fn))\n",
    "                mlflow.log_metric(\"true_positives\", int(tp))\n",
    "                \n",
    "                if model_name in baseline_results:\n",
    "                    baseline_metrics = baseline_results[model_name]\n",
    "                    improvement_roc = (performance_metrics['roc_auc'] - baseline_metrics['roc_auc']) * 100\n",
    "                    improvement_f1 = (performance_metrics['f1_score'] - baseline_metrics['f1_score']) * 100\n",
    "                    \n",
    "                    mlflow.log_metric(\"improvement_roc_auc\", improvement_roc)\n",
    "                    mlflow.log_metric(\"improvement_f1_score\", improvement_f1)\n",
    "                \n",
    "                # Graphiques\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "                \n",
    "                fpr, tpr, _ = roc_curve(y_test, test_probabilities)\n",
    "                axes[0].plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {performance_metrics[\"roc_auc\"]:.3f})')\n",
    "                axes[0].plot([0, 1], [0, 1], 'k--')\n",
    "                axes[0].set_xlabel('False Positive Rate')\n",
    "                axes[0].set_ylabel('True Positive Rate')\n",
    "                axes[0].set_title(f'ROC Curve - {model_name}')\n",
    "                axes[0].legend()\n",
    "                axes[0].grid(alpha=0.3)\n",
    "                \n",
    "                cm_display = ConfusionMatrixDisplay(performance_metrics['confusion_mat'])\n",
    "                cm_display.plot(ax=axes[1], cmap='Blues')\n",
    "                axes[1].set_title(f'Confusion Matrix - {model_name}')\n",
    "                \n",
    "                plots_path = f\"evaluation_{model_name}.png\"\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(plots_path, dpi=150, bbox_inches='tight')\n",
    "                mlflow.log_artifact(plots_path)\n",
    "                plt.close()\n",
    "                os.remove(plots_path)\n",
    "                \n",
    "                print(f\"   âœ“ ROC-AUC: {performance_metrics['roc_auc']:.4f}\")\n",
    "                print(f\"   âœ“ F1-Score: {performance_metrics['f1_score']:.4f}\")\n",
    "                print(f\"   âœ“ Run ID: {run.info.run_id}\")\n",
    "                print()\n",
    "                \n",
    "                mlflow.set_tag(\"stage\", \"evaluation\")\n",
    "                mlflow.set_tag(\"model_name\", model_name)\n",
    "                \n",
    "            except Exception as error:\n",
    "                print(f\"   âŒ Erreur: {str(error)}\\n\")\n",
    "                mlflow.log_param(\"status\", \"failed\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"âœ… Ã‰VALUATION TERMINÃ‰E\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return optimized_performance\n",
    "\n",
    "\n",
    "tuned_results = evaluate_optimized_models_with_mlflow(\n",
    "    optimized_models, X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7399153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“Š TABLEAU COMPARATIF DES PERFORMANCES\n",
      "================================================================================\n",
      "\n",
      "                          ModÃ¨le Baseline ROC-AUC OptimisÃ© ROC-AUC Î” ROC-AUC Baseline F1 OptimisÃ© F1   Î” F1\n",
      "                         XGBoost           0.9995           0.9997    +0.02%      0.9640      0.9737 +0.96%\n",
      "                        LightGBM           0.9995           0.9997    +0.02%      0.9667      0.9724 +0.57%\n",
      "                   Random Forest           0.9971           0.9975    +0.04%      0.9174      0.9173 -0.01%\n",
      "                        CatBoost           0.9998           0.9998    +0.00%      0.9715      0.9715 +0.00%\n",
      "Logistic Regression (ElasticNet)           0.9998           0.9999    +0.01%      0.9488      0.9549 +0.61%\n",
      "\n",
      "================================================================================\n",
      "ğŸ† MEILLEUR MODÃˆLE: Logistic Regression (ElasticNet)\n",
      "   â€¢ ROC-AUC: 0.9999\n",
      "   â€¢ F1-Score: 0.9549\n",
      "   â€¢ Recall: 1.0000\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7. TABLEAU COMPARATIF\n",
    "# ============================================================\n",
    "\n",
    "def display_performance_comparison(baseline_results, tuned_results):\n",
    "    \"\"\"\n",
    "    Affiche un tableau comparatif\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸ“Š TABLEAU COMPARATIF DES PERFORMANCES\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_name in baseline_results.keys():\n",
    "        if model_name in tuned_results:\n",
    "            baseline = baseline_results[model_name]\n",
    "            tuned = tuned_results[model_name]\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'ModÃ¨le': model_name,\n",
    "                'Baseline ROC-AUC': f\"{baseline['roc_auc']:.4f}\",\n",
    "                'OptimisÃ© ROC-AUC': f\"{tuned['roc_auc']:.4f}\",\n",
    "                'Î” ROC-AUC': f\"{(tuned['roc_auc'] - baseline['roc_auc'])*100:+.2f}%\",\n",
    "                'Baseline F1': f\"{baseline['f1_score']:.4f}\",\n",
    "                'OptimisÃ© F1': f\"{tuned['f1_score']:.4f}\",\n",
    "                'Î” F1': f\"{(tuned['f1_score'] - baseline['f1_score'])*100:+.2f}%\"\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(comparison_df.to_string(index=False))\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    \n",
    "    best_model_name = max(tuned_results, key=lambda x: tuned_results[x]['roc_auc'])\n",
    "    best_roc_auc = tuned_results[best_model_name]['roc_auc']\n",
    "    \n",
    "    print(f\"ğŸ† MEILLEUR MODÃˆLE: {best_model_name}\")\n",
    "    print(f\"   â€¢ ROC-AUC: {best_roc_auc:.4f}\")\n",
    "    print(f\"   â€¢ F1-Score: {tuned_results[best_model_name]['f1_score']:.4f}\")\n",
    "    print(f\"   â€¢ Recall: {tuned_results[best_model_name]['recall']:.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "\n",
    "comparison_table = display_performance_comparison(baseline_results, tuned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf55e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ—ï¸  CONSTRUCTION DES MODÃˆLES D'ENSEMBLE\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¦ Estimateurs de base (5):\n",
      "   1. XGBoost\n",
      "   2. LightGBM\n",
      "   3. Random Forest\n",
      "   4. CatBoost\n",
      "   5. Logistic Regression (ElasticNet)\n",
      "\n",
      "ğŸ§  Meta-Learner (Stacking):\n",
      "   â€¢ Type: LogisticRegression\n",
      "\n",
      "ğŸ”§ Construction du Stacking Classifier...\n",
      "\n",
      "ğŸ”§ Construction du Voting Classifier...\n",
      "   âœ“ Mode: Soft voting avec pondÃ©ration\n",
      "\n",
      "================================================================================\n",
      "âœ… ModÃ¨les d'ensemble construits avec succÃ¨s!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 8. ENSEMBLE LEARNING\n",
    "# ============================================================\n",
    "\n",
    "def build_ensemble_models(optimized_models, meta_learner_config=None):\n",
    "    \"\"\"\n",
    "    Construit des modÃ¨les d'ensemble\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸ—ï¸  CONSTRUCTION DES MODÃˆLES D'ENSEMBLE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    base_estimators = [(name, model) for name, model in optimized_models.items()]\n",
    "    \n",
    "    print(f\"ğŸ“¦ Estimateurs de base ({len(base_estimators)}):\")\n",
    "    for idx, (estimator_name, _) in enumerate(base_estimators, 1):\n",
    "        print(f\"   {idx}. {estimator_name}\")\n",
    "    \n",
    "    if meta_learner_config is None:\n",
    "        meta_learner = LogisticRegression(\n",
    "            penalty='elasticnet',\n",
    "            C=0.5,\n",
    "            l1_ratio=0.3,\n",
    "            solver='saga',\n",
    "            max_iter=1500,\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        meta_learner = meta_learner_config\n",
    "    \n",
    "    print(f\"\\nğŸ§  Meta-Learner (Stacking):\")\n",
    "    print(f\"   â€¢ Type: {type(meta_learner).__name__}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”§ Construction du Stacking Classifier...\")\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=meta_learner,\n",
    "        cv=5,\n",
    "        stack_method='predict_proba',\n",
    "        n_jobs=-1,\n",
    "        passthrough=False,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ”§ Construction du Voting Classifier...\")\n",
    "    \n",
    "    if 'tuned_results' in globals():\n",
    "        weights = [tuned_results[name]['roc_auc'] for name in optimized_models.keys()]\n",
    "        print(f\"   âœ“ Mode: Soft voting avec pondÃ©ration\")\n",
    "    else:\n",
    "        weights = None\n",
    "        print(f\"   âœ“ Mode: Soft voting sans pondÃ©ration\")\n",
    "    \n",
    "    voting_model = VotingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        voting='soft',\n",
    "        weights=weights,\n",
    "        n_jobs=-1,\n",
    "        flatten_transform=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    ensemble_collection = {\n",
    "        'Stacking Ensemble': stacking_model,\n",
    "        'Weighted Voting Ensemble': voting_model\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"âœ… ModÃ¨les d'ensemble construits avec succÃ¨s!\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return ensemble_collection\n",
    "\n",
    "\n",
    "ensemble_models = build_ensemble_models(optimized_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ ENSEMBLES AVEC MLFLOW\n",
      "================================================================================\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [1/2] Stacking Ensemble                                          â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   ğŸ”„ EntraÃ®nement...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Stacking_Ensemble'.\n",
      "Created version '1' of model 'Stacking_Ensemble'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ“ ROC-AUC: 0.9999\n",
      "   âœ“ F1-Score: 0.9846\n",
      "   âœ“ Temps: 232.89s\n",
      "   âœ“ Run ID: 5584788fcb374dea90885d4486b53536\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ [2/2] Weighted Voting Ensemble                                   â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   ğŸ”„ EntraÃ®nement...\n",
      "   âŒ Erreur: The estimator XGBClassifier should be a classifier.\n",
      "\n",
      "================================================================================\n",
      "âœ… ENSEMBLES TERMINÃ‰S\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 9. ENTRAÃNEMENT DES ENSEMBLES\n",
    "# ============================================================\n",
    "\n",
    "def train_and_evaluate_ensembles_with_mlflow(ensemble_models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    EntraÃ®ne et Ã©value les ensembles avec MLflow\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸš€ ENSEMBLES AVEC MLFLOW\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    ensemble_performance = {}\n",
    "    \n",
    "    for ensemble_idx, (ensemble_name, ensemble_model) in enumerate(ensemble_models.items(), 1):\n",
    "        print(f\"â•”{'â•'*78}â•—\")\n",
    "        print(f\"â•‘ [{ensemble_idx}/{len(ensemble_models)}] {ensemble_name:<58} â•‘\")\n",
    "        print(f\"â•š{'â•'*78}â•\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"{ensemble_name}\") as run:\n",
    "            train_start = time.time()\n",
    "            \n",
    "            try:\n",
    "                mlflow.log_param(\"model_type\", type(ensemble_model).__name__)\n",
    "                mlflow.log_param(\"model_category\", \"Ensemble\")\n",
    "                mlflow.log_param(\"n_base_estimators\", len(ensemble_model.estimators))\n",
    "                \n",
    "                print(f\"   ğŸ”„ EntraÃ®nement...\")\n",
    "                ensemble_model.fit(X_train, y_train)\n",
    "                training_duration = time.time() - train_start\n",
    "                \n",
    "                predictions = ensemble_model.predict(X_test)\n",
    "                prediction_probas = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "                \n",
    "                ensemble_metrics = {\n",
    "                    'model_object': ensemble_model,\n",
    "                    'accuracy': accuracy_score(y_test, predictions),\n",
    "                    'precision': precision_score(y_test, predictions, zero_division=0),\n",
    "                    'recall': recall_score(y_test, predictions, zero_division=0),\n",
    "                    'f1_score': f1_score(y_test, predictions, zero_division=0),\n",
    "                    'roc_auc': roc_auc_score(y_test, prediction_probas),\n",
    "                    'training_time': training_duration,\n",
    "                    'predictions': predictions,\n",
    "                    'prediction_probas': prediction_probas,\n",
    "                    'confusion_matrix': confusion_matrix(y_test, predictions),\n",
    "                    'run_id': run.info.run_id\n",
    "                }\n",
    "                \n",
    "                ensemble_performance[ensemble_name] = ensemble_metrics\n",
    "                \n",
    "                mlflow.log_metric(\"accuracy\", ensemble_metrics['accuracy'])\n",
    "                mlflow.log_metric(\"precision\", ensemble_metrics['precision'])\n",
    "                mlflow.log_metric(\"recall\", ensemble_metrics['recall'])\n",
    "                mlflow.log_metric(\"f1_score\", ensemble_metrics['f1_score'])\n",
    "                mlflow.log_metric(\"roc_auc\", ensemble_metrics['roc_auc'])\n",
    "                mlflow.log_metric(\"training_time\", training_duration)\n",
    "                \n",
    "                tn, fp, fn, tp = ensemble_metrics['confusion_matrix'].ravel()\n",
    "                mlflow.log_metric(\"true_negatives\", int(tn))\n",
    "                mlflow.log_metric(\"false_positives\", int(fp))\n",
    "                mlflow.log_metric(\"false_negatives\", int(fn))\n",
    "                mlflow.log_metric(\"true_positives\", int(tp))\n",
    "                \n",
    "                try:\n",
    "                    signature = infer_signature(X_train, prediction_probas)\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        ensemble_model,\n",
    "                        artifact_path=\"ensemble_model\",\n",
    "                        signature=signature,\n",
    "                        registered_model_name=f\"{ensemble_name.replace(' ', '_')}\"\n",
    "                    )\n",
    "                except:\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        ensemble_model,\n",
    "                        artifact_path=\"ensemble_model\",\n",
    "                        registered_model_name=f\"{ensemble_name.replace(' ', '_')}\"\n",
    "                    )\n",
    "                \n",
    "                fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "                \n",
    "                fpr, tpr, _ = roc_curve(y_test, prediction_probas)\n",
    "                axes[0].plot(fpr, tpr, linewidth=3, label=f'ROC (AUC = {ensemble_metrics[\"roc_auc\"]:.3f})')\n",
    "                axes[0].plot([0, 1], [0, 1], 'k--')\n",
    "                axes[0].set_xlabel('False Positive Rate')\n",
    "                axes[0].set_ylabel('True Positive Rate')\n",
    "                axes[0].set_title(f'ROC Curve - {ensemble_name}')\n",
    "                axes[0].legend()\n",
    "                axes[0].grid(alpha=0.3)\n",
    "                \n",
    "                cm_display = ConfusionMatrixDisplay(ensemble_metrics['confusion_matrix'])\n",
    "                cm_display.plot(ax=axes[1], cmap='Greens')\n",
    "                axes[1].set_title(f'Confusion Matrix - {ensemble_name}')\n",
    "                \n",
    "                ensemble_plots_path = f\"ensemble_{ensemble_name.replace(' ', '_')}.png\"\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(ensemble_plots_path, dpi=150, bbox_inches='tight')\n",
    "                mlflow.log_artifact(ensemble_plots_path)\n",
    "                plt.close()\n",
    "                os.remove(ensemble_plots_path)\n",
    "                \n",
    "                print(f\"   âœ“ ROC-AUC: {ensemble_metrics['roc_auc']:.4f}\")\n",
    "                print(f\"   âœ“ F1-Score: {ensemble_metrics['f1_score']:.4f}\")\n",
    "                print(f\"   âœ“ Temps: {training_duration:.2f}s\")\n",
    "                print(f\"   âœ“ Run ID: {run.info.run_id}\")\n",
    "                print()\n",
    "                \n",
    "                mlflow.set_tag(\"stage\", \"ensemble\")\n",
    "                mlflow.set_tag(\"model_name\", ensemble_name)\n",
    "                \n",
    "            except Exception as error:\n",
    "                print(f\"   âŒ Erreur: {str(error)}\\n\")\n",
    "                mlflow.log_param(\"status\", \"failed\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"âœ… ENSEMBLES TERMINÃ‰S\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return ensemble_performance\n",
    "\n",
    "\n",
    "ensemble_results = train_and_evaluate_ensembles_with_mlflow(\n",
    "    ensemble_models, X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfffd41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ† COMPARAISON COMPLÃˆTE DE TOUS LES MODÃˆLES\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Classement par ROC-AUC:\n",
      "\n",
      "                                     ModÃ¨le     Type  ROC-AUC  F1-Score   Recall  Precision\n",
      "Logistic Regression (ElasticNet) (OptimisÃ©) OptimisÃ© 0.999900  0.954897 1.000000   0.913687\n",
      "                          Stacking Ensemble Ensemble 0.999896  0.984615 0.993252   0.976127\n",
      "Logistic Regression (ElasticNet) (Baseline) Baseline 0.999817  0.948784 1.000000   0.902558\n",
      "                        CatBoost (Baseline) Baseline 0.999789  0.971504 0.989204   0.954427\n",
      "                        CatBoost (OptimisÃ©) OptimisÃ© 0.999789  0.971504 0.989204   0.954427\n",
      "                        LightGBM (OptimisÃ©) OptimisÃ© 0.999744  0.972428 0.975709   0.969169\n",
      "                         XGBoost (OptimisÃ©) OptimisÃ© 0.999704  0.973666 0.973009   0.974324\n",
      "                        LightGBM (Baseline) Baseline 0.999535  0.966711 0.979757   0.954008\n",
      "                         XGBoost (Baseline) Baseline 0.999531  0.964048 0.977058   0.951380\n",
      "                   Random Forest (OptimisÃ©) OptimisÃ© 0.997474  0.917333 0.928475   0.906456\n",
      "                   Random Forest (Baseline) Baseline 0.997076  0.917431 0.944669   0.891720\n",
      "\n",
      "================================================================================\n",
      "ğŸ¥‡ MODÃˆLE CHAMPION: Logistic Regression (ElasticNet) (OptimisÃ©)\n",
      "================================================================================\n",
      "   â€¢ ROC-AUC:   0.9999\n",
      "   â€¢ F1-Score:  0.9549\n",
      "   â€¢ Recall:    1.0000\n",
      "   â€¢ Precision: 0.9137\n",
      "================================================================================\n",
      "\n",
      "âœ… SCRIPT TERMINÃ‰ AVEC SUCCÃˆS!\n",
      "ğŸ¯ Champion: Logistic Regression (ElasticNet) (OptimisÃ©)\n",
      "ğŸ“Š ROC-AUC: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 10. COMPARAISON COMPLÃˆTE\n",
    "# ============================================================\n",
    "\n",
    "def comprehensive_model_comparison(baseline_results, tuned_results, ensemble_results):\n",
    "    \"\"\"\n",
    "    Compare tous les modÃ¨les\n",
    "    \"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"ğŸ† COMPARAISON COMPLÃˆTE DE TOUS LES MODÃˆLES\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for model_name, metrics in baseline_results.items():\n",
    "        all_results.append({\n",
    "            'ModÃ¨le': f\"{model_name} (Baseline)\",\n",
    "            'Type': 'Baseline',\n",
    "            'ROC-AUC': metrics['roc_auc'],\n",
    "            'F1-Score': metrics['f1_score'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'Precision': metrics['precision']\n",
    "        })\n",
    "    \n",
    "    for model_name, metrics in tuned_results.items():\n",
    "        all_results.append({\n",
    "            'ModÃ¨le': f\"{model_name} (OptimisÃ©)\",\n",
    "            'Type': 'OptimisÃ©',\n",
    "            'ROC-AUC': metrics['roc_auc'],\n",
    "            'F1-Score': metrics['f1_score'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'Precision': metrics['precision']\n",
    "        })\n",
    "    \n",
    "    for model_name, metrics in ensemble_results.items():\n",
    "        all_results.append({\n",
    "            'ModÃ¨le': model_name,\n",
    "            'Type': 'Ensemble',\n",
    "            'ROC-AUC': metrics['roc_auc'],\n",
    "            'F1-Score': metrics['f1_score'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'Precision': metrics['precision']\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(all_results)\n",
    "    comparison_df = comparison_df.sort_values('ROC-AUC', ascending=False)\n",
    "    \n",
    "    print(\"ğŸ“Š Classement par ROC-AUC:\\n\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    champion = comparison_df.iloc[0]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ¥‡ MODÃˆLE CHAMPION: {champion['ModÃ¨le']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"   â€¢ ROC-AUC:   {champion['ROC-AUC']:.4f}\")\n",
    "    print(f\"   â€¢ F1-Score:  {champion['F1-Score']:.4f}\")\n",
    "    print(f\"   â€¢ Recall:    {champion['Recall']:.4f}\")\n",
    "    print(f\"   â€¢ Precision: {champion['Precision']:.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return comparison_df, champion\n",
    "\n",
    "\n",
    "full_comparison_df, best_model_info = comprehensive_model_comparison(\n",
    "    baseline_results, \n",
    "    tuned_results, \n",
    "    ensemble_results\n",
    ")\n",
    "\n",
    "\n",
    "print(\"âœ… SCRIPT TERMINÃ‰ AVEC SUCCÃˆS!\")\n",
    "print(f\"ğŸ¯ Champion: {best_model_info['ModÃ¨le']}\")\n",
    "print(f\"ğŸ“Š ROC-AUC: {best_model_info['ROC-AUC']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
